{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "a283cf21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.image import pad_to_bounding_box\n",
    "from tensorflow.image import central_crop\n",
    "from tensorflow.image import resize\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.preprocessing import image\n",
    " \n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from tensorflow.keras.applications.imagenet_utils import decode_predictions\n",
    "from tensorflow.keras.applications.imagenet_utils import preprocess_input\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.preprocessing.image import img_to_array, load_img, array_to_img\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,EarlyStopping\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "9a75b93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=[]\n",
    "for i in range(60):\n",
    "    img=Image.open(f'tf_image/test_{i:03d}.jpg').convert(\"RGB\")\n",
    "    img.resize((500, 150)).save(f'tf_image/test_{i:03d}.jpg')\n",
    "    X_test.append(image.img_to_array(img)/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "0fa2b255",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=[]\n",
    "for i in range(200):\n",
    "    img=Image.open(f'tf_image/train_{i:03d}.jpg').convert(\"RGB\")\n",
    "    img.resize((500, 150)).save(f'tf_image/train_{i:03d}.jpg')\n",
    "    X_train.append(image.img_to_array(img)/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "6ba20daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train= np.asarray(X_train)\n",
    "X_test = np.asarray(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "34aa8e21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 150, 500, 3)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "821d4074",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 150, 500, 3)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "a95ab7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=[i//10 for i in range(200)]\n",
    "y_test=[i//3 for i in range(60)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "ef0125a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train, num_classes = 20)\n",
    "y_test = to_categorical(y_test, num_classes=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "3d44f85d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "665dcb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), input_shape=(150, 500, 3), activation='relu'))  \n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))   # 25% 만큼이 제외되고 75%만 훈련에 참가한다\n",
    "model.add(Flatten())      # Flatten 한다음에 Dense가 나옴 \n",
    "model.add(Dense(128,  activation='relu'))\n",
    "model.add(Dropout(0.5)) # 절반 떨굼\n",
    "model.add(Dense(20, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "edd5a800",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "29f544c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelpath=\"./data/model/MNIST_CNN.hdf5\"\n",
    "checkpointer = ModelCheckpoint(filepath=modelpath, monitor='loss', verbose=1, save_best_only=True)\n",
    "early_stopping_callback = EarlyStopping(monitor='loss', patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "8ff4099c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: loss improved from inf to 3.03393, saving model to ./data/model\\MNIST_CNN.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2: loss did not improve from 3.03393\n",
      "\n",
      "Epoch 3: loss did not improve from 3.03393\n",
      "\n",
      "Epoch 4: loss did not improve from 3.03393\n",
      "\n",
      "Epoch 5: loss did not improve from 3.03393\n",
      "\n",
      "Epoch 6: loss improved from 3.03393 to 2.83163, saving model to ./data/model\\MNIST_CNN.hdf5\n",
      "\n",
      "Epoch 7: loss did not improve from 2.83163\n",
      "\n",
      "Epoch 8: loss did not improve from 2.83163\n",
      "\n",
      "Epoch 9: loss improved from 2.83163 to 2.23913, saving model to ./data/model\\MNIST_CNN.hdf5\n",
      "\n",
      "Epoch 10: loss did not improve from 2.23913\n",
      "\n",
      "Epoch 11: loss improved from 2.23913 to 2.08753, saving model to ./data/model\\MNIST_CNN.hdf5\n",
      "\n",
      "Epoch 12: loss improved from 2.08753 to 1.99034, saving model to ./data/model\\MNIST_CNN.hdf5\n",
      "\n",
      "Epoch 13: loss improved from 1.99034 to 1.93105, saving model to ./data/model\\MNIST_CNN.hdf5\n",
      "\n",
      "Epoch 14: loss improved from 1.93105 to 1.66226, saving model to ./data/model\\MNIST_CNN.hdf5\n",
      "\n",
      "Epoch 15: loss improved from 1.66226 to 1.44676, saving model to ./data/model\\MNIST_CNN.hdf5\n",
      "\n",
      "Epoch 16: loss improved from 1.44676 to 1.16686, saving model to ./data/model\\MNIST_CNN.hdf5\n",
      "\n",
      "Epoch 17: loss improved from 1.16686 to 1.08007, saving model to ./data/model\\MNIST_CNN.hdf5\n",
      "\n",
      "Epoch 18: loss improved from 1.08007 to 0.80459, saving model to ./data/model\\MNIST_CNN.hdf5\n",
      "\n",
      "Epoch 19: loss improved from 0.80459 to 0.65001, saving model to ./data/model\\MNIST_CNN.hdf5\n",
      "\n",
      "Epoch 20: loss improved from 0.65001 to 0.55326, saving model to ./data/model\\MNIST_CNN.hdf5\n",
      "\n",
      "Epoch 21: loss improved from 0.55326 to 0.36459, saving model to ./data/model\\MNIST_CNN.hdf5\n",
      "\n",
      "Epoch 22: loss improved from 0.36459 to 0.28863, saving model to ./data/model\\MNIST_CNN.hdf5\n",
      "\n",
      "Epoch 23: loss improved from 0.28863 to 0.18294, saving model to ./data/model\\MNIST_CNN.hdf5\n",
      "\n",
      "Epoch 24: loss improved from 0.18294 to 0.12447, saving model to ./data/model\\MNIST_CNN.hdf5\n",
      "\n",
      "Epoch 25: loss did not improve from 0.12447\n",
      "\n",
      "Epoch 26: loss improved from 0.12447 to 0.04994, saving model to ./data/model\\MNIST_CNN.hdf5\n",
      "\n",
      "Epoch 27: loss did not improve from 0.04994\n",
      "\n",
      "Epoch 28: loss improved from 0.04994 to 0.03192, saving model to ./data/model\\MNIST_CNN.hdf5\n",
      "\n",
      "Epoch 29: loss did not improve from 0.03192\n",
      "\n",
      "Epoch 30: loss improved from 0.03192 to 0.02290, saving model to ./data/model\\MNIST_CNN.hdf5\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=30, batch_size=200, verbose=0, callbacks=[early_stopping_callback,checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "8e1770ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 283ms/step - loss: 1.8477 - accuracy: 0.6500\n",
      "\n",
      " Test Accuracy: 0.6500\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n Test Accuracy: %.4f\" % (model.evaluate(X_test, y_test)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9280ac5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

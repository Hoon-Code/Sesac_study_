{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13791769",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "파이토치\n",
    "- n차원 텐서\n",
    "- 신경망 구성하고 학습하는 과정에서의 자동 미분\n",
    "비전분야(이미지, 영상) -> 3차원 텐서 (batch size, width, height)\n",
    "자연어 처리 분야 -> 3차원 텐서 (batch size, length, dimension)   =>분야에 따라 표현 방법이 다름\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "527d9f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9f7306",
   "metadata": {},
   "outputs": [],
   "source": [
    "#넘파이로 텐서를 만드는 방법 \n",
    "#1차원 텐서"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f86785c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t=np.array([1,2,3,4])\n",
    "t\n",
    "t.ndim #몇차원 텐서\n",
    "t.shape #텐서의 크기, (4,)는 (1,4)를 의미함 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "59317d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.array([[1., 2., 3.], [4., 5., 6.], [7., 8., 9.], [10., 11., 12.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "158e1b94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t\n",
    "t.ndim #몇 차원 텐서\n",
    "t.shape #텐서의 크기 (4,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4b75a6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#파이토치로 텐서 만드는 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e733de20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#클래스 : 설계도면, 붕어빵기계, 벽돌공장\n",
    "#객체: 클래스로부터 생성되는 실체\n",
    "# 설계도면 -> 실제건물\n",
    "# 붕어빵기계 -> 붕어빵\n",
    "# 벽돌공장 -> 벽돌\n",
    "# 메서드 : 객체가 수행하는 동작(기능)\n",
    "# 속성(어트리뷰트) :객체의 특성 \n",
    "# 객체지향(적) 프로그래밍\n",
    "# ex) 절차지향적 사례\n",
    "# -붕어빵 기계로 붕업빵을 판매하던 시대가 지나가고 잉어빵 시대가 도래, 붕어빵 기계는 못쓰게 됨 \n",
    "# ->잉어빵 기계 새롭게 제작\n",
    "# ex)객체지향적 사례\n",
    "# 붕어빵 기계로 붕어빵을 판매하던 시대가 지나가고\n",
    "# 잉어빵 시대가 도래, 붕어빵 기계를 재사용(붕어빵 기계의 메서드, 속성 중에서 그대로 사용할 것은 사용하고,\n",
    "#                        변경할것은 변경, 버릴것은 버리고)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7901413e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-2.1.0-cp311-cp311-win_amd64.whl.metadata (25 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch) (4.7.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch) (1.11.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch) (2023.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\user\\anaconda3\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Downloading torch-2.1.0-cp311-cp311-win_amd64.whl (192.3 MB)\n",
      "   ---------------------------------------- 0.0/192.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.4/192.3 MB 11.6 MB/s eta 0:00:17\n",
      "   ---------------------------------------- 1.0/192.3 MB 15.1 MB/s eta 0:00:13\n",
      "   ---------------------------------------- 1.7/192.3 MB 18.1 MB/s eta 0:00:11\n",
      "    --------------------------------------- 2.6/192.3 MB 18.2 MB/s eta 0:00:11\n",
      "    --------------------------------------- 3.6/192.3 MB 20.8 MB/s eta 0:00:10\n",
      "    --------------------------------------- 4.7/192.3 MB 23.3 MB/s eta 0:00:09\n",
      "   - -------------------------------------- 5.9/192.3 MB 25.2 MB/s eta 0:00:08\n",
      "   - -------------------------------------- 7.4/192.3 MB 26.2 MB/s eta 0:00:08\n",
      "   - -------------------------------------- 8.7/192.3 MB 27.8 MB/s eta 0:00:07\n",
      "   -- ------------------------------------- 9.7/192.3 MB 28.2 MB/s eta 0:00:07\n",
      "   -- ------------------------------------- 10.7/192.3 MB 28.4 MB/s eta 0:00:07\n",
      "   -- ------------------------------------- 11.8/192.3 MB 31.2 MB/s eta 0:00:06\n",
      "   -- ------------------------------------- 12.9/192.3 MB 32.8 MB/s eta 0:00:06\n",
      "   -- ------------------------------------- 13.9/192.3 MB 32.7 MB/s eta 0:00:06\n",
      "   --- ------------------------------------ 14.9/192.3 MB 31.2 MB/s eta 0:00:06\n",
      "   --- ------------------------------------ 15.9/192.3 MB 31.2 MB/s eta 0:00:06\n",
      "   --- ------------------------------------ 16.8/192.3 MB 29.7 MB/s eta 0:00:06\n",
      "   --- ------------------------------------ 17.7/192.3 MB 28.4 MB/s eta 0:00:07\n",
      "   --- ------------------------------------ 18.7/192.3 MB 28.5 MB/s eta 0:00:07\n",
      "   ---- ----------------------------------- 19.6/192.3 MB 28.5 MB/s eta 0:00:07\n",
      "   ---- ----------------------------------- 20.3/192.3 MB 27.3 MB/s eta 0:00:07\n",
      "   ---- ----------------------------------- 21.0/192.3 MB 26.2 MB/s eta 0:00:07\n",
      "   ---- ----------------------------------- 21.7/192.3 MB 25.1 MB/s eta 0:00:07\n",
      "   ---- ----------------------------------- 22.4/192.3 MB 25.2 MB/s eta 0:00:07\n",
      "   ---- ----------------------------------- 23.1/192.3 MB 23.4 MB/s eta 0:00:08\n",
      "   ---- ----------------------------------- 23.1/192.3 MB 23.4 MB/s eta 0:00:08\n",
      "   ---- ----------------------------------- 23.1/192.3 MB 23.4 MB/s eta 0:00:08\n",
      "   ---- ----------------------------------- 23.1/192.3 MB 23.4 MB/s eta 0:00:08\n",
      "   ---- ----------------------------------- 23.1/192.3 MB 23.4 MB/s eta 0:00:08\n",
      "   ---- ----------------------------------- 23.1/192.3 MB 23.4 MB/s eta 0:00:08\n",
      "   ---- ----------------------------------- 23.1/192.3 MB 23.4 MB/s eta 0:00:08\n",
      "   ---- ----------------------------------- 23.8/192.3 MB 15.6 MB/s eta 0:00:11\n",
      "   ----- ---------------------------------- 24.5/192.3 MB 15.2 MB/s eta 0:00:12\n",
      "   ----- ---------------------------------- 25.4/192.3 MB 14.9 MB/s eta 0:00:12\n",
      "   ----- ---------------------------------- 26.3/192.3 MB 15.2 MB/s eta 0:00:11\n",
      "   ----- ---------------------------------- 27.1/192.3 MB 14.9 MB/s eta 0:00:12\n",
      "   ----- ---------------------------------- 28.0/192.3 MB 14.9 MB/s eta 0:00:12\n",
      "   ----- ---------------------------------- 28.8/192.3 MB 14.6 MB/s eta 0:00:12\n",
      "   ------ --------------------------------- 29.4/192.3 MB 13.9 MB/s eta 0:00:12\n",
      "   ------ --------------------------------- 30.0/192.3 MB 13.9 MB/s eta 0:00:12\n",
      "   ------ --------------------------------- 30.8/192.3 MB 13.6 MB/s eta 0:00:12\n",
      "   ------ --------------------------------- 31.5/192.3 MB 13.9 MB/s eta 0:00:12\n",
      "   ------ --------------------------------- 32.2/192.3 MB 13.6 MB/s eta 0:00:12\n",
      "   ------ --------------------------------- 33.0/192.3 MB 13.6 MB/s eta 0:00:12\n",
      "   ------ --------------------------------- 33.5/192.3 MB 19.8 MB/s eta 0:00:09\n",
      "   ------- -------------------------------- 33.8/192.3 MB 18.2 MB/s eta 0:00:09\n",
      "   ------- -------------------------------- 34.4/192.3 MB 18.2 MB/s eta 0:00:09\n",
      "   ------- -------------------------------- 34.9/192.3 MB 17.7 MB/s eta 0:00:09\n",
      "   ------- -------------------------------- 35.6/192.3 MB 17.7 MB/s eta 0:00:09\n",
      "   ------- -------------------------------- 36.0/192.3 MB 17.3 MB/s eta 0:00:10\n",
      "   ------- -------------------------------- 36.5/192.3 MB 16.4 MB/s eta 0:00:10\n",
      "   ------- -------------------------------- 36.9/192.3 MB 16.0 MB/s eta 0:00:10\n",
      "   ------- -------------------------------- 37.6/192.3 MB 16.0 MB/s eta 0:00:10\n",
      "   ------- -------------------------------- 38.2/192.3 MB 15.6 MB/s eta 0:00:10\n",
      "   -------- ------------------------------- 38.7/192.3 MB 15.6 MB/s eta 0:00:10\n",
      "   -------- ------------------------------- 39.1/192.3 MB 15.6 MB/s eta 0:00:10\n",
      "   -------- ------------------------------- 39.6/192.3 MB 15.2 MB/s eta 0:00:11\n",
      "   -------- ------------------------------- 40.0/192.3 MB 14.9 MB/s eta 0:00:11\n",
      "   -------- ------------------------------- 40.3/192.3 MB 14.6 MB/s eta 0:00:11\n",
      "   -------- ------------------------------- 40.7/192.3 MB 14.2 MB/s eta 0:00:11\n",
      "   -------- ------------------------------- 41.0/192.3 MB 13.6 MB/s eta 0:00:12\n",
      "   -------- ------------------------------- 41.2/192.3 MB 13.1 MB/s eta 0:00:12\n",
      "   -------- ------------------------------- 41.5/192.3 MB 12.8 MB/s eta 0:00:12\n",
      "   -------- ------------------------------- 41.7/192.3 MB 12.6 MB/s eta 0:00:12\n",
      "   -------- ------------------------------- 42.0/192.3 MB 12.1 MB/s eta 0:00:13\n",
      "   -------- ------------------------------- 42.4/192.3 MB 11.7 MB/s eta 0:00:13\n",
      "   -------- ------------------------------- 42.7/192.3 MB 11.7 MB/s eta 0:00:13\n",
      "   -------- ------------------------------- 43.0/192.3 MB 11.5 MB/s eta 0:00:13\n",
      "   -------- ------------------------------- 43.3/192.3 MB 10.9 MB/s eta 0:00:14\n",
      "   --------- ------------------------------ 43.5/192.3 MB 10.7 MB/s eta 0:00:14\n",
      "   --------- ------------------------------ 43.9/192.3 MB 10.9 MB/s eta 0:00:14\n",
      "   --------- ------------------------------ 44.3/192.3 MB 10.7 MB/s eta 0:00:14\n",
      "   --------- ------------------------------ 44.5/192.3 MB 10.6 MB/s eta 0:00:15\n",
      "   --------- ------------------------------ 44.8/192.3 MB 10.2 MB/s eta 0:00:15\n",
      "   --------- ------------------------------ 45.1/192.3 MB 10.1 MB/s eta 0:00:15\n",
      "   --------- ------------------------------ 45.4/192.3 MB 9.9 MB/s eta 0:00:15\n",
      "   --------- ------------------------------ 45.9/192.3 MB 9.9 MB/s eta 0:00:15\n",
      "   --------- ------------------------------ 46.3/192.3 MB 9.9 MB/s eta 0:00:15\n",
      "   --------- ------------------------------ 46.6/192.3 MB 9.6 MB/s eta 0:00:16\n",
      "   --------- ------------------------------ 46.9/192.3 MB 9.6 MB/s eta 0:00:16\n",
      "   --------- ------------------------------ 47.2/192.3 MB 9.5 MB/s eta 0:00:16\n",
      "   --------- ------------------------------ 47.4/192.3 MB 9.2 MB/s eta 0:00:16\n",
      "   --------- ------------------------------ 47.6/192.3 MB 9.1 MB/s eta 0:00:16\n",
      "   --------- ------------------------------ 47.9/192.3 MB 9.0 MB/s eta 0:00:17\n",
      "   ---------- ----------------------------- 48.1/192.3 MB 8.7 MB/s eta 0:00:17\n",
      "   ---------- ----------------------------- 48.3/192.3 MB 8.6 MB/s eta 0:00:17\n",
      "   ---------- ----------------------------- 48.5/192.3 MB 8.5 MB/s eta 0:00:17\n",
      "   ---------- ----------------------------- 48.9/192.3 MB 8.3 MB/s eta 0:00:18\n",
      "   ---------- ----------------------------- 49.3/192.3 MB 8.4 MB/s eta 0:00:18\n",
      "   ---------- ----------------------------- 49.7/192.3 MB 8.3 MB/s eta 0:00:18\n",
      "   ---------- ----------------------------- 50.1/192.3 MB 8.3 MB/s eta 0:00:18\n",
      "   ---------- ----------------------------- 50.4/192.3 MB 8.3 MB/s eta 0:00:18\n",
      "   ---------- ----------------------------- 50.7/192.3 MB 8.2 MB/s eta 0:00:18\n",
      "   ---------- ----------------------------- 51.0/192.3 MB 8.2 MB/s eta 0:00:18\n",
      "   ---------- ----------------------------- 51.2/192.3 MB 8.1 MB/s eta 0:00:18\n",
      "   ---------- ----------------------------- 51.5/192.3 MB 8.2 MB/s eta 0:00:18\n",
      "   ---------- ----------------------------- 51.8/192.3 MB 8.3 MB/s eta 0:00:17\n",
      "   ---------- ----------------------------- 52.1/192.3 MB 8.2 MB/s eta 0:00:18\n",
      "   ---------- ----------------------------- 52.4/192.3 MB 8.2 MB/s eta 0:00:18\n",
      "   ---------- ----------------------------- 52.4/192.3 MB 8.3 MB/s eta 0:00:17\n",
      "   ---------- ----------------------------- 52.7/192.3 MB 7.9 MB/s eta 0:00:18\n",
      "   ----------- ---------------------------- 52.9/192.3 MB 7.9 MB/s eta 0:00:18\n",
      "   ----------- ---------------------------- 53.2/192.3 MB 7.9 MB/s eta 0:00:18\n",
      "   ----------- ---------------------------- 53.5/192.3 MB 7.9 MB/s eta 0:00:18\n",
      "   ----------- ---------------------------- 53.9/192.3 MB 8.0 MB/s eta 0:00:18\n",
      "   ----------- ---------------------------- 54.2/192.3 MB 7.9 MB/s eta 0:00:18\n",
      "   ----------- ---------------------------- 54.5/192.3 MB 7.9 MB/s eta 0:00:18\n",
      "   ----------- ---------------------------- 54.7/192.3 MB 7.8 MB/s eta 0:00:18\n",
      "   ----------- ---------------------------- 55.0/192.3 MB 7.8 MB/s eta 0:00:18\n",
      "   ----------- ---------------------------- 55.2/192.3 MB 7.8 MB/s eta 0:00:18\n",
      "   ----------- ---------------------------- 55.6/192.3 MB 7.9 MB/s eta 0:00:18\n",
      "   ----------- ---------------------------- 56.0/192.3 MB 7.9 MB/s eta 0:00:18\n",
      "   ----------- ---------------------------- 56.2/192.3 MB 7.7 MB/s eta 0:00:18\n",
      "   ----------- ---------------------------- 56.5/192.3 MB 7.7 MB/s eta 0:00:18\n",
      "   ----------- ---------------------------- 56.8/192.3 MB 7.7 MB/s eta 0:00:18\n",
      "   ----------- ---------------------------- 57.1/192.3 MB 7.7 MB/s eta 0:00:18\n",
      "   ----------- ---------------------------- 57.5/192.3 MB 7.8 MB/s eta 0:00:18\n",
      "   ------------ --------------------------- 57.8/192.3 MB 7.9 MB/s eta 0:00:18\n",
      "   ------------ --------------------------- 58.2/192.3 MB 8.0 MB/s eta 0:00:17\n",
      "   ------------ --------------------------- 58.5/192.3 MB 8.2 MB/s eta 0:00:17\n",
      "   ------------ --------------------------- 58.9/192.3 MB 8.2 MB/s eta 0:00:17\n",
      "   ------------ --------------------------- 59.3/192.3 MB 8.3 MB/s eta 0:00:17\n",
      "   ------------ --------------------------- 59.7/192.3 MB 8.3 MB/s eta 0:00:17\n",
      "   ------------ --------------------------- 60.1/192.3 MB 8.2 MB/s eta 0:00:17\n",
      "   ------------ --------------------------- 60.5/192.3 MB 8.4 MB/s eta 0:00:16\n",
      "   ------------ --------------------------- 60.9/192.3 MB 8.5 MB/s eta 0:00:16\n",
      "   ------------ --------------------------- 61.3/192.3 MB 8.5 MB/s eta 0:00:16\n",
      "   ------------ --------------------------- 61.7/192.3 MB 8.7 MB/s eta 0:00:15\n",
      "   ------------ --------------------------- 62.1/192.3 MB 8.8 MB/s eta 0:00:15\n",
      "   ------------- -------------------------- 62.6/192.3 MB 9.0 MB/s eta 0:00:15\n",
      "   ------------- -------------------------- 63.0/192.3 MB 9.4 MB/s eta 0:00:14\n",
      "   ------------- -------------------------- 63.3/192.3 MB 9.5 MB/s eta 0:00:14\n",
      "   ------------- -------------------------- 63.7/192.3 MB 9.8 MB/s eta 0:00:14\n",
      "   ------------- -------------------------- 64.2/192.3 MB 9.8 MB/s eta 0:00:14\n",
      "   ------------- -------------------------- 64.7/192.3 MB 10.1 MB/s eta 0:00:13\n",
      "   ------------- -------------------------- 65.1/192.3 MB 10.4 MB/s eta 0:00:13\n",
      "   ------------- -------------------------- 65.6/192.3 MB 10.4 MB/s eta 0:00:13\n",
      "   ------------- -------------------------- 65.9/192.3 MB 10.6 MB/s eta 0:00:12\n",
      "   ------------- -------------------------- 66.3/192.3 MB 10.6 MB/s eta 0:00:12\n",
      "   ------------- -------------------------- 66.6/192.3 MB 10.6 MB/s eta 0:00:12\n",
      "   ------------- -------------------------- 67.0/192.3 MB 10.7 MB/s eta 0:00:12\n",
      "   ------------- -------------------------- 67.3/192.3 MB 10.7 MB/s eta 0:00:12\n",
      "   -------------- ------------------------- 67.6/192.3 MB 10.7 MB/s eta 0:00:12\n",
      "   -------------- ------------------------- 68.0/192.3 MB 10.7 MB/s eta 0:00:12\n",
      "   -------------- ------------------------- 68.4/192.3 MB 10.9 MB/s eta 0:00:12\n",
      "   -------------- ------------------------- 68.8/192.3 MB 10.9 MB/s eta 0:00:12\n",
      "   -------------- ------------------------- 69.2/192.3 MB 10.9 MB/s eta 0:00:12\n",
      "   -------------- ------------------------- 69.6/192.3 MB 10.9 MB/s eta 0:00:12\n",
      "   -------------- ------------------------- 70.0/192.3 MB 10.9 MB/s eta 0:00:12\n",
      "   -------------- ------------------------- 70.4/192.3 MB 10.9 MB/s eta 0:00:12\n",
      "   -------------- ------------------------- 70.7/192.3 MB 10.9 MB/s eta 0:00:12\n",
      "   -------------- ------------------------- 71.1/192.3 MB 10.7 MB/s eta 0:00:12\n",
      "   -------------- ------------------------- 71.6/192.3 MB 10.9 MB/s eta 0:00:12\n",
      "   -------------- ------------------------- 71.9/192.3 MB 10.9 MB/s eta 0:00:12\n",
      "   --------------- ------------------------ 72.3/192.3 MB 10.9 MB/s eta 0:00:12\n",
      "   --------------- ------------------------ 72.7/192.3 MB 10.7 MB/s eta 0:00:12\n",
      "   --------------- ------------------------ 73.0/192.3 MB 10.7 MB/s eta 0:00:12\n",
      "   --------------- ------------------------ 73.3/192.3 MB 10.7 MB/s eta 0:00:12\n",
      "   --------------- ------------------------ 73.6/192.3 MB 10.6 MB/s eta 0:00:12\n",
      "   --------------- ------------------------ 73.9/192.3 MB 10.4 MB/s eta 0:00:12\n",
      "   --------------- ------------------------ 74.2/192.3 MB 10.4 MB/s eta 0:00:12\n",
      "   --------------- ------------------------ 74.5/192.3 MB 10.1 MB/s eta 0:00:12\n",
      "   --------------- ------------------------ 74.7/192.3 MB 9.9 MB/s eta 0:00:12\n",
      "   --------------- ------------------------ 74.9/192.3 MB 9.8 MB/s eta 0:00:13\n",
      "   --------------- ------------------------ 75.1/192.3 MB 9.5 MB/s eta 0:00:13\n",
      "   --------------- ------------------------ 75.4/192.3 MB 9.5 MB/s eta 0:00:13\n",
      "   --------------- ------------------------ 75.7/192.3 MB 9.4 MB/s eta 0:00:13\n",
      "   --------------- ------------------------ 75.9/192.3 MB 9.2 MB/s eta 0:00:13\n",
      "   --------------- ------------------------ 76.1/192.3 MB 9.1 MB/s eta 0:00:13\n",
      "   --------------- ------------------------ 76.4/192.3 MB 9.1 MB/s eta 0:00:13\n",
      "   --------------- ------------------------ 76.7/192.3 MB 9.0 MB/s eta 0:00:13\n",
      "   ---------------- ----------------------- 76.9/192.3 MB 8.8 MB/s eta 0:00:14\n",
      "   ---------------- ----------------------- 77.2/192.3 MB 8.8 MB/s eta 0:00:14\n",
      "   ---------------- ----------------------- 77.5/192.3 MB 8.7 MB/s eta 0:00:14\n",
      "   ---------------- ----------------------- 77.7/192.3 MB 8.7 MB/s eta 0:00:14\n",
      "   ---------------- ----------------------- 78.0/192.3 MB 8.7 MB/s eta 0:00:14\n",
      "   ---------------- ----------------------- 78.3/192.3 MB 8.6 MB/s eta 0:00:14\n",
      "   ---------------- ----------------------- 78.6/192.3 MB 8.5 MB/s eta 0:00:14\n",
      "   ---------------- ----------------------- 78.8/192.3 MB 8.4 MB/s eta 0:00:14\n",
      "   ---------------- ----------------------- 79.1/192.3 MB 8.3 MB/s eta 0:00:14\n",
      "   ---------------- ----------------------- 79.5/192.3 MB 8.3 MB/s eta 0:00:14\n",
      "   ---------------- ----------------------- 79.8/192.3 MB 8.3 MB/s eta 0:00:14\n",
      "   ---------------- ----------------------- 80.1/192.3 MB 8.2 MB/s eta 0:00:14\n",
      "   ---------------- ----------------------- 80.4/192.3 MB 8.2 MB/s eta 0:00:14\n",
      "   ---------------- ----------------------- 80.7/192.3 MB 8.2 MB/s eta 0:00:14\n",
      "   ---------------- ----------------------- 81.0/192.3 MB 8.0 MB/s eta 0:00:14\n",
      "   ---------------- ----------------------- 81.4/192.3 MB 8.1 MB/s eta 0:00:14\n",
      "   ----------------- ---------------------- 81.7/192.3 MB 8.1 MB/s eta 0:00:14\n",
      "   ----------------- ---------------------- 82.2/192.3 MB 8.0 MB/s eta 0:00:14\n",
      "   ----------------- ---------------------- 82.6/192.3 MB 8.1 MB/s eta 0:00:14\n",
      "   ----------------- ---------------------- 82.9/192.3 MB 8.1 MB/s eta 0:00:14\n",
      "   ----------------- ---------------------- 83.2/192.3 MB 8.0 MB/s eta 0:00:14\n",
      "   ----------------- ---------------------- 83.5/192.3 MB 8.0 MB/s eta 0:00:14\n",
      "   ----------------- ---------------------- 83.9/192.3 MB 8.2 MB/s eta 0:00:14\n",
      "   ----------------- ---------------------- 84.3/192.3 MB 8.2 MB/s eta 0:00:14\n",
      "   ----------------- ---------------------- 84.7/192.3 MB 8.3 MB/s eta 0:00:13\n",
      "   ----------------- ---------------------- 85.1/192.3 MB 8.6 MB/s eta 0:00:13\n",
      "   ----------------- ---------------------- 85.6/192.3 MB 8.6 MB/s eta 0:00:13\n",
      "   ----------------- ---------------------- 86.0/192.3 MB 9.0 MB/s eta 0:00:12\n",
      "   ----------------- ---------------------- 86.5/192.3 MB 9.2 MB/s eta 0:00:12\n",
      "   ------------------ --------------------- 86.9/192.3 MB 9.4 MB/s eta 0:00:12\n",
      "   ------------------ --------------------- 87.4/192.3 MB 9.6 MB/s eta 0:00:11\n",
      "   ------------------ --------------------- 87.7/192.3 MB 9.8 MB/s eta 0:00:11\n",
      "   ------------------ --------------------- 88.0/192.3 MB 9.8 MB/s eta 0:00:11\n",
      "   ------------------ --------------------- 88.3/192.3 MB 9.8 MB/s eta 0:00:11\n",
      "   ------------------ --------------------- 88.6/192.3 MB 9.9 MB/s eta 0:00:11\n",
      "   ------------------ --------------------- 89.0/192.3 MB 9.9 MB/s eta 0:00:11\n",
      "   ------------------ --------------------- 89.3/192.3 MB 10.1 MB/s eta 0:00:11\n",
      "   ------------------ --------------------- 89.7/192.3 MB 10.1 MB/s eta 0:00:11\n",
      "   ------------------ --------------------- 90.0/192.3 MB 10.2 MB/s eta 0:00:11\n",
      "   ------------------ --------------------- 90.4/192.3 MB 10.1 MB/s eta 0:00:11\n",
      "   ------------------ --------------------- 90.7/192.3 MB 10.2 MB/s eta 0:00:10\n",
      "   ------------------ --------------------- 91.1/192.3 MB 10.4 MB/s eta 0:00:10\n",
      "   ------------------- -------------------- 91.5/192.3 MB 10.4 MB/s eta 0:00:10\n",
      "   ------------------- -------------------- 91.9/192.3 MB 10.4 MB/s eta 0:00:10\n",
      "   ------------------- -------------------- 92.3/192.3 MB 10.4 MB/s eta 0:00:10\n",
      "   ------------------- -------------------- 92.5/192.3 MB 10.2 MB/s eta 0:00:10\n",
      "   ------------------- -------------------- 92.9/192.3 MB 10.2 MB/s eta 0:00:10\n",
      "   ------------------- -------------------- 93.2/192.3 MB 10.2 MB/s eta 0:00:10\n",
      "   ------------------- -------------------- 93.5/192.3 MB 10.4 MB/s eta 0:00:10\n",
      "   ------------------- -------------------- 93.9/192.3 MB 10.2 MB/s eta 0:00:10\n",
      "   ------------------- -------------------- 94.2/192.3 MB 10.1 MB/s eta 0:00:10\n",
      "   ------------------- -------------------- 94.5/192.3 MB 9.9 MB/s eta 0:00:10\n",
      "   ------------------- -------------------- 94.8/192.3 MB 9.9 MB/s eta 0:00:10\n",
      "   ------------------- -------------------- 95.1/192.3 MB 9.9 MB/s eta 0:00:10\n",
      "   ------------------- -------------------- 95.5/192.3 MB 9.8 MB/s eta 0:00:10\n",
      "   ------------------- -------------------- 95.9/192.3 MB 9.8 MB/s eta 0:00:10\n",
      "   -------------------- ------------------- 96.3/192.3 MB 9.8 MB/s eta 0:00:10\n",
      "   -------------------- ------------------- 96.7/192.3 MB 9.9 MB/s eta 0:00:10\n",
      "   -------------------- ------------------- 97.2/192.3 MB 9.8 MB/s eta 0:00:10\n",
      "   -------------------- ------------------- 97.6/192.3 MB 9.8 MB/s eta 0:00:10\n",
      "   -------------------- ------------------- 98.0/192.3 MB 9.8 MB/s eta 0:00:10\n",
      "   -------------------- ------------------- 98.3/192.3 MB 9.8 MB/s eta 0:00:10\n",
      "   -------------------- ------------------- 98.8/192.3 MB 9.9 MB/s eta 0:00:10\n",
      "   -------------------- ------------------- 99.2/192.3 MB 10.1 MB/s eta 0:00:10\n",
      "   -------------------- ------------------- 99.5/192.3 MB 9.9 MB/s eta 0:00:10\n",
      "   -------------------- ------------------- 99.9/192.3 MB 10.1 MB/s eta 0:00:10\n",
      "   -------------------- ------------------ 100.2/192.3 MB 10.1 MB/s eta 0:00:10\n",
      "   -------------------- ------------------- 100.6/192.3 MB 9.9 MB/s eta 0:00:10\n",
      "   -------------------- ------------------- 100.9/192.3 MB 9.9 MB/s eta 0:00:10\n",
      "   -------------------- ------------------ 101.2/192.3 MB 10.1 MB/s eta 0:00:10\n",
      "   --------------------- ------------------ 101.6/192.3 MB 9.9 MB/s eta 0:00:10\n",
      "   --------------------- ------------------ 101.9/192.3 MB 9.8 MB/s eta 0:00:10\n",
      "   --------------------- ------------------ 102.1/192.3 MB 9.8 MB/s eta 0:00:10\n",
      "   --------------------- ------------------ 102.5/192.3 MB 9.6 MB/s eta 0:00:10\n",
      "   --------------------- ------------------ 102.8/192.3 MB 9.8 MB/s eta 0:00:10\n",
      "   --------------------- ------------------ 103.2/192.3 MB 9.8 MB/s eta 0:00:10\n",
      "   --------------------- ------------------ 103.5/192.3 MB 9.8 MB/s eta 0:00:10\n",
      "   --------------------- ------------------ 103.9/192.3 MB 9.8 MB/s eta 0:00:10\n",
      "   --------------------- ------------------ 104.2/192.3 MB 9.9 MB/s eta 0:00:09\n",
      "   --------------------- ------------------ 104.5/192.3 MB 9.8 MB/s eta 0:00:09\n",
      "   --------------------- ------------------ 104.8/192.3 MB 9.9 MB/s eta 0:00:09\n",
      "   --------------------- ------------------ 105.2/192.3 MB 9.9 MB/s eta 0:00:09\n",
      "   --------------------- ------------------ 105.5/192.3 MB 9.9 MB/s eta 0:00:09\n",
      "   ---------------------- ----------------- 105.9/192.3 MB 9.8 MB/s eta 0:00:09\n",
      "   ---------------------- ----------------- 106.2/192.3 MB 9.8 MB/s eta 0:00:09\n",
      "   ---------------------- ----------------- 106.6/192.3 MB 9.8 MB/s eta 0:00:09\n",
      "   ---------------------- ----------------- 107.1/192.3 MB 9.8 MB/s eta 0:00:09\n",
      "   ---------------------- ----------------- 107.6/192.3 MB 9.9 MB/s eta 0:00:09\n",
      "   ---------------------- ----------------- 108.0/192.3 MB 9.8 MB/s eta 0:00:09\n",
      "   ---------------------- ----------------- 108.3/192.3 MB 9.8 MB/s eta 0:00:09\n",
      "   ---------------------- ----------------- 108.7/192.3 MB 9.8 MB/s eta 0:00:09\n",
      "   ---------------------- ----------------- 109.0/192.3 MB 9.6 MB/s eta 0:00:09\n",
      "   ---------------------- ----------------- 109.3/192.3 MB 9.6 MB/s eta 0:00:09\n",
      "   ---------------------- ----------------- 109.6/192.3 MB 9.6 MB/s eta 0:00:09\n",
      "   ---------------------- ----------------- 110.0/192.3 MB 9.8 MB/s eta 0:00:09\n",
      "   ---------------------- ----------------- 110.4/192.3 MB 9.6 MB/s eta 0:00:09\n",
      "   ----------------------- ---------------- 110.8/192.3 MB 9.8 MB/s eta 0:00:09\n",
      "   ----------------------- ---------------- 111.2/192.3 MB 9.8 MB/s eta 0:00:09\n",
      "   ----------------------- ---------------- 111.5/192.3 MB 9.8 MB/s eta 0:00:09\n",
      "   ----------------------- ---------------- 112.0/192.3 MB 9.9 MB/s eta 0:00:09\n",
      "   ---------------------- ---------------- 112.4/192.3 MB 10.2 MB/s eta 0:00:08\n",
      "   ---------------------- ---------------- 112.9/192.3 MB 10.2 MB/s eta 0:00:08\n",
      "   ---------------------- ---------------- 113.4/192.3 MB 10.4 MB/s eta 0:00:08\n",
      "   ----------------------- --------------- 113.9/192.3 MB 10.4 MB/s eta 0:00:08\n",
      "   ----------------------- --------------- 114.4/192.3 MB 10.7 MB/s eta 0:00:08\n",
      "   ----------------------- --------------- 114.9/192.3 MB 10.9 MB/s eta 0:00:08\n",
      "   ----------------------- --------------- 115.4/192.3 MB 11.1 MB/s eta 0:00:07\n",
      "   ----------------------- --------------- 115.8/192.3 MB 11.3 MB/s eta 0:00:07\n",
      "   ----------------------- --------------- 116.3/192.3 MB 11.7 MB/s eta 0:00:07\n",
      "   ----------------------- --------------- 116.7/192.3 MB 11.5 MB/s eta 0:00:07\n",
      "   ----------------------- --------------- 117.1/192.3 MB 11.5 MB/s eta 0:00:07\n",
      "   ----------------------- --------------- 117.5/192.3 MB 11.5 MB/s eta 0:00:07\n",
      "   ----------------------- --------------- 118.0/192.3 MB 11.3 MB/s eta 0:00:07\n",
      "   ------------------------ -------------- 118.5/192.3 MB 11.5 MB/s eta 0:00:07\n",
      "   ------------------------ -------------- 118.9/192.3 MB 11.7 MB/s eta 0:00:07\n",
      "   ------------------------ -------------- 119.3/192.3 MB 11.9 MB/s eta 0:00:07\n",
      "   ------------------------ -------------- 119.8/192.3 MB 12.1 MB/s eta 0:00:06\n",
      "   ------------------------ -------------- 120.4/192.3 MB 12.4 MB/s eta 0:00:06\n",
      "   ------------------------ -------------- 120.9/192.3 MB 12.3 MB/s eta 0:00:06\n",
      "   ------------------------ -------------- 121.4/192.3 MB 12.8 MB/s eta 0:00:06\n",
      "   ------------------------ -------------- 121.6/192.3 MB 12.9 MB/s eta 0:00:06\n",
      "   ------------------------ -------------- 121.6/192.3 MB 12.9 MB/s eta 0:00:06\n",
      "   ------------------------ -------------- 121.7/192.3 MB 11.5 MB/s eta 0:00:07\n",
      "   ------------------------ -------------- 122.3/192.3 MB 11.7 MB/s eta 0:00:06\n",
      "   ------------------------ -------------- 123.0/192.3 MB 11.9 MB/s eta 0:00:06\n",
      "   ------------------------- ------------- 123.6/192.3 MB 11.9 MB/s eta 0:00:06\n",
      "   ------------------------- ------------- 124.3/192.3 MB 11.9 MB/s eta 0:00:06\n",
      "   ------------------------- ------------- 125.0/192.3 MB 12.1 MB/s eta 0:00:06\n",
      "   ------------------------- ------------- 125.6/192.3 MB 12.1 MB/s eta 0:00:06\n",
      "   ------------------------- ------------- 126.1/192.3 MB 12.1 MB/s eta 0:00:06\n",
      "   ------------------------- ------------- 126.6/192.3 MB 12.4 MB/s eta 0:00:06\n",
      "   ------------------------- ------------- 127.2/192.3 MB 12.4 MB/s eta 0:00:06\n",
      "   ------------------------- ------------- 127.7/192.3 MB 12.4 MB/s eta 0:00:06\n",
      "   -------------------------- ------------ 128.2/192.3 MB 12.6 MB/s eta 0:00:06\n",
      "   -------------------------- ------------ 128.8/192.3 MB 12.4 MB/s eta 0:00:06\n",
      "   -------------------------- ------------ 129.3/192.3 MB 12.6 MB/s eta 0:00:06\n",
      "   -------------------------- ------------ 129.8/192.3 MB 12.6 MB/s eta 0:00:05\n",
      "   -------------------------- ------------ 130.4/192.3 MB 12.6 MB/s eta 0:00:05\n",
      "   -------------------------- ------------ 130.9/192.3 MB 12.6 MB/s eta 0:00:05\n",
      "   -------------------------- ------------ 131.4/192.3 MB 12.4 MB/s eta 0:00:05\n",
      "   -------------------------- ------------ 131.9/192.3 MB 14.2 MB/s eta 0:00:05\n",
      "   -------------------------- ------------ 132.4/192.3 MB 13.6 MB/s eta 0:00:05\n",
      "   -------------------------- ------------ 132.8/192.3 MB 13.6 MB/s eta 0:00:05\n",
      "   --------------------------- ----------- 133.3/192.3 MB 13.4 MB/s eta 0:00:05\n",
      "   --------------------------- ----------- 133.8/192.3 MB 13.4 MB/s eta 0:00:05\n",
      "   --------------------------- ----------- 134.4/192.3 MB 13.4 MB/s eta 0:00:05\n",
      "   --------------------------- ----------- 135.0/192.3 MB 13.4 MB/s eta 0:00:05\n",
      "   --------------------------- ----------- 135.5/192.3 MB 13.1 MB/s eta 0:00:05\n",
      "   --------------------------- ----------- 136.0/192.3 MB 13.1 MB/s eta 0:00:05\n",
      "   --------------------------- ----------- 136.4/192.3 MB 13.1 MB/s eta 0:00:05\n",
      "   --------------------------- ----------- 136.9/192.3 MB 12.8 MB/s eta 0:00:05\n",
      "   --------------------------- ----------- 137.3/192.3 MB 12.8 MB/s eta 0:00:05\n",
      "   --------------------------- ----------- 137.4/192.3 MB 12.6 MB/s eta 0:00:05\n",
      "   --------------------------- ----------- 137.4/192.3 MB 12.6 MB/s eta 0:00:05\n",
      "   --------------------------- ----------- 137.4/192.3 MB 12.6 MB/s eta 0:00:05\n",
      "   --------------------------- ----------- 137.4/192.3 MB 12.6 MB/s eta 0:00:05\n",
      "   --------------------------- ----------- 137.4/192.3 MB 10.4 MB/s eta 0:00:06\n",
      "   --------------------------- ----------- 137.8/192.3 MB 10.1 MB/s eta 0:00:06\n",
      "   ---------------------------- ----------- 138.1/192.3 MB 9.9 MB/s eta 0:00:06\n",
      "   ---------------------------- ----------- 138.4/192.3 MB 9.6 MB/s eta 0:00:06\n",
      "   ---------------------------- ----------- 138.8/192.3 MB 9.6 MB/s eta 0:00:06\n",
      "   ---------------------------- ----------- 139.1/192.3 MB 9.4 MB/s eta 0:00:06\n",
      "   ---------------------------- ----------- 139.4/192.3 MB 9.2 MB/s eta 0:00:06\n",
      "   ----------------------------- ---------- 139.7/192.3 MB 9.1 MB/s eta 0:00:06\n",
      "   ----------------------------- ---------- 140.1/192.3 MB 9.0 MB/s eta 0:00:06\n",
      "   ----------------------------- ---------- 140.4/192.3 MB 8.8 MB/s eta 0:00:06\n",
      "   ----------------------------- ---------- 140.8/192.3 MB 8.7 MB/s eta 0:00:06\n",
      "   ----------------------------- ---------- 141.1/192.3 MB 8.7 MB/s eta 0:00:06\n",
      "   ----------------------------- ---------- 141.4/192.3 MB 8.5 MB/s eta 0:00:06\n",
      "   ----------------------------- ---------- 141.8/192.3 MB 8.5 MB/s eta 0:00:06\n",
      "   ----------------------------- ---------- 142.2/192.3 MB 8.4 MB/s eta 0:00:06\n",
      "   ----------------------------- ---------- 142.6/192.3 MB 8.5 MB/s eta 0:00:06\n",
      "   ----------------------------- ---------- 143.0/192.3 MB 8.4 MB/s eta 0:00:06\n",
      "   ----------------------------- ---------- 143.3/192.3 MB 8.4 MB/s eta 0:00:06\n",
      "   ----------------------------- ---------- 143.7/192.3 MB 8.2 MB/s eta 0:00:06\n",
      "   ----------------------------- ---------- 144.1/192.3 MB 8.2 MB/s eta 0:00:06\n",
      "   ------------------------------ --------- 144.5/192.3 MB 8.1 MB/s eta 0:00:06\n",
      "   ------------------------------ --------- 144.8/192.3 MB 8.1 MB/s eta 0:00:06\n",
      "   ------------------------------ --------- 145.1/192.3 MB 7.9 MB/s eta 0:00:06\n",
      "   ------------------------------ --------- 145.5/192.3 MB 7.9 MB/s eta 0:00:06\n",
      "   ------------------------------ --------- 145.8/192.3 MB 7.8 MB/s eta 0:00:06\n",
      "   ------------------------------ --------- 146.2/192.3 MB 7.8 MB/s eta 0:00:06\n",
      "   ------------------------------ --------- 146.6/192.3 MB 7.7 MB/s eta 0:00:06\n",
      "   ------------------------------ --------- 146.9/192.3 MB 7.6 MB/s eta 0:00:06\n",
      "   ------------------------------ --------- 147.3/192.3 MB 7.5 MB/s eta 0:00:06\n",
      "   ------------------------------ --------- 147.6/192.3 MB 7.6 MB/s eta 0:00:06\n",
      "   ------------------------------ --------- 147.9/192.3 MB 8.7 MB/s eta 0:00:06\n",
      "   ------------------------------ --------- 148.4/192.3 MB 9.0 MB/s eta 0:00:05\n",
      "   ------------------------------ --------- 148.8/192.3 MB 9.1 MB/s eta 0:00:05\n",
      "   ------------------------------- -------- 149.3/192.3 MB 9.4 MB/s eta 0:00:05\n",
      "   ------------------------------- -------- 149.7/192.3 MB 9.4 MB/s eta 0:00:05\n",
      "   ------------------------------- -------- 150.1/192.3 MB 9.6 MB/s eta 0:00:05\n",
      "   ------------------------------- -------- 150.7/192.3 MB 9.8 MB/s eta 0:00:05\n",
      "   ------------------------------- -------- 151.0/192.3 MB 9.8 MB/s eta 0:00:05\n",
      "   ------------------------------- -------- 151.0/192.3 MB 9.8 MB/s eta 0:00:05\n",
      "   ------------------------------- -------- 151.0/192.3 MB 9.8 MB/s eta 0:00:05\n",
      "   ------------------------------- -------- 151.0/192.3 MB 9.8 MB/s eta 0:00:05\n",
      "   ------------------------------- -------- 151.3/192.3 MB 8.6 MB/s eta 0:00:05\n",
      "   ------------------------------- -------- 152.2/192.3 MB 9.1 MB/s eta 0:00:05\n",
      "   ------------------------------- -------- 153.1/192.3 MB 9.5 MB/s eta 0:00:05\n",
      "   ------------------------------- ------- 154.0/192.3 MB 10.1 MB/s eta 0:00:04\n",
      "   ------------------------------- ------- 154.9/192.3 MB 10.7 MB/s eta 0:00:04\n",
      "   ------------------------------- ------- 156.0/192.3 MB 11.5 MB/s eta 0:00:04\n",
      "   ------------------------------- ------- 156.9/192.3 MB 12.4 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 157.3/192.3 MB 12.8 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 157.3/192.3 MB 12.8 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 157.3/192.3 MB 12.8 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 157.3/192.3 MB 12.8 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 157.8/192.3 MB 11.3 MB/s eta 0:00:04\n",
      "   -------------------------------- ------ 158.8/192.3 MB 11.9 MB/s eta 0:00:03\n",
      "   -------------------------------- ------ 160.0/192.3 MB 12.9 MB/s eta 0:00:03\n",
      "   -------------------------------- ------ 161.2/192.3 MB 14.2 MB/s eta 0:00:03\n",
      "   -------------------------------- ------ 162.1/192.3 MB 18.2 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 163.1/192.3 MB 18.2 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 164.2/192.3 MB 18.7 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 165.6/192.3 MB 19.3 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 166.6/192.3 MB 19.3 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 167.7/192.3 MB 27.3 MB/s eta 0:00:01\n",
      "   ---------------------------------- ---- 169.0/192.3 MB 28.5 MB/s eta 0:00:01\n",
      "   ---------------------------------- ---- 170.1/192.3 MB 28.5 MB/s eta 0:00:01\n",
      "   ---------------------------------- ---- 170.9/192.3 MB 28.5 MB/s eta 0:00:01\n",
      "   ---------------------------------- ---- 171.7/192.3 MB 27.3 MB/s eta 0:00:01\n",
      "   ---------------------------------- ---- 172.0/192.3 MB 27.3 MB/s eta 0:00:01\n",
      "   ---------------------------------- ---- 172.0/192.3 MB 27.3 MB/s eta 0:00:01\n",
      "   ---------------------------------- ---- 172.0/192.3 MB 27.3 MB/s eta 0:00:01\n",
      "   ---------------------------------- ---- 172.0/192.3 MB 27.3 MB/s eta 0:00:01\n",
      "   ---------------------------------- ---- 172.0/192.3 MB 27.3 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 172.8/192.3 MB 18.2 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 174.6/192.3 MB 18.7 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 176.2/192.3 MB 19.3 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 177.2/192.3 MB 19.3 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 178.1/192.3 MB 19.3 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 179.3/192.3 MB 19.3 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 180.7/192.3 MB 19.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 182.1/192.3 MB 21.1 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 183.4/192.3 MB 36.3 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 184.4/192.3 MB 34.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 185.5/192.3 MB 32.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 186.4/192.3 MB 31.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  187.5/192.3 MB 32.8 MB/s eta 0:00:01\n",
      "   --------------------------------------  188.6/192.3 MB 31.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  189.7/192.3 MB 31.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  190.8/192.3 MB 31.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  191.8/192.3 MB 29.8 MB/s eta 0:00:01\n",
      "   --------------------------------------  192.3/192.3 MB 29.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  192.3/192.3 MB 29.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  192.3/192.3 MB 29.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  192.3/192.3 MB 29.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  192.3/192.3 MB 29.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  192.3/192.3 MB 29.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  192.3/192.3 MB 29.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  192.3/192.3 MB 29.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  192.3/192.3 MB 29.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  192.3/192.3 MB 29.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  192.3/192.3 MB 29.7 MB/s eta 0:00:01\n",
      "   --------------------------------------- 192.3/192.3 MB 13.9 MB/s eta 0:00:00\n",
      "Installing collected packages: torch\n",
      "Successfully installed torch-2.1.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7d446c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fa684bae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 2., 3., 4., 5., 6.])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t=torch.FloatTensor([0., 1., 2., 3., 4., 5., 6.])\n",
    "t\n",
    "#클래스(FloatTensor) : 대문자로 시작 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "27b8a223",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.dim()\n",
    "t.shape  #속성\n",
    "t.size() #함수(메서드), 내차.달린다()  자동차(클래스)\n",
    "# '자동차'클래스로부터 파생된 실체(객체)가 '내차'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "889516c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nclass FloatTensor:\\n    속성 (특성)\\n    함수 (동작)\\n'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "class FloatTensor:\n",
    "    속성 (특성)\n",
    "    함수 (동작)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c887bf61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 2., 3., 4., 5., 6.])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "07365cea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "83d2084f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2., 3., 4.])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[2:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0969559a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 2.])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "acf38b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.FloatTensor([[1., 2., 3.],\n",
    "                       [4., 5., 6.],\n",
    "                       [7., 8., 9.],\n",
    "                       [10., 11., 12.]\n",
    "                      ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bec446b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  2.,  3.],\n",
       "        [ 4.,  5.,  6.],\n",
       "        [ 7.,  8.,  9.],\n",
       "        [10., 11., 12.]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6c621443",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.dim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9e5587c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6a740cd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2.,  5.,  8., 11.])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[:,1] #2번째 차원의 첫번째만 가지고 온다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "53b6ba55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[:,1].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f64bd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 행렬 연산(덧셈,뺄셈) : 두 행렬의 크기가 같아야 함\n",
    "# 행렬 연산(곱셈)   : 두행렬의 마지막 차원과 첫번째 차원이 일치\n",
    "# 브로드 캐스팅 : 두 행렬 크기를 맞춰서 연산 가능토록 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2d928804",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1=torch.FloatTensor([[1,1]])\n",
    "t2=torch.FloatTensor([[2,2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d06c5c08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3., 3.]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1.shape\n",
    "t1+t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "beecf182",
   "metadata": {},
   "outputs": [],
   "source": [
    "t3=torch.FloatTensor([[1,1]])  #(1,2)\n",
    "t4=torch.FloatTensor([[3]])  #(1,) -> (1,2) =>브로드캐스팅됨(자동 변경)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b32779ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4., 4.]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t3+t4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "904c307c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2*1 + 1*2\n",
    "t5=torch.FloatTensor([[1,3]])  #[[1,3],\n",
    "                               #[1,3]] 으로 브로드 캐스팅 됨\n",
    "t6=torch.FloatTensor([[1],[3]])  #[[1],     [[1],[1],\n",
    "                                 #[3]]      [3],[3]]     으로 브로드 캐스팅 됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c32faf81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t5.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "920352be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t6.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "83c3b04d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 4.],\n",
       "        [4., 6.]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t5+t6  #(2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b4c91ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "m1 = torch.FloatTensor([[1, 2], [3, 4]])\n",
    "m2 = torch.FloatTensor([[1], [2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d7015768",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8b14d4d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7de39814",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5.],\n",
       "        [11.]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1.matmul(m2) #matmul= 행렬 곱셈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9307225a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2.],\n",
       "        [6., 8.]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1*m2       #m2에서 브로드캐스팅이 발생해 2*2로 변환되어 요소간 곱셈 발생"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "750dc19e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2.],\n",
       "        [3., 4.]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t=torch.FloatTensor([[1,2],[3,4]])\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "34eeec8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.5000)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "989cd909",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2., 3.])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.mean(dim=0)  # 차원을 줘서 평균을 구할수 있음 -> dim=0은 첫번째 차원, 행렬에서는 행단위로 평균 구해짐 \n",
    "# -> 행에 해당하는 차원을 제거 한다(열만 남긴다) = 2차원 구조 행렬 -> 1차원 벡터로 바뀜 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "16f9af76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.5000, 3.5000])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.mean(dim=1) #dim=1은 두번째 차원, 행렬에서는 열, 열을 제거 -> 행만 남음 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e730402b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "eef19c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "t=torch.FloatTensor([[1,2],[3,4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "60f6dcbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2.],\n",
       "        [3., 4.]])"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "e044d550",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(10.)"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "01fa6ce8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4., 6.])"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.sum(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "e06ba79a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 7.])"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.sum(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "1eb393e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 7.])"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.sum(dim=-1)  #마지막 차원 제거함 = 열 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "d4745f55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.)"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "8eb81404",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.max(\n",
       "values=tensor([3., 4.]),\n",
       "indices=tensor([1, 1]))"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.max(dim=0)  #행 제거  , indeices=argmax : 최대값의 인덱스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "16ba084e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "b1cd19d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "aeebc53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.array([[[0, 1, 2],\n",
    "               [3, 4, 5]],\n",
    "              [[6, 7, 8],\n",
    "               [9, 10, 11]]])\n",
    "ft = torch.FloatTensor(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "0b298669",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.,  1.,  2.],\n",
       "         [ 3.,  4.,  5.]],\n",
       "\n",
       "        [[ 6.,  7.,  8.],\n",
       "         [ 9., 10., 11.]]])"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "1f47d67f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2, 3])"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "fa1ebf8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  1.,  2.],\n",
       "        [ 3.,  4.,  5.],\n",
       "        [ 6.,  7.,  8.],\n",
       "        [ 9., 10., 11.]])"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#view : 텐서 크기 변경 함수, (-1,3)은 (?,3)으로 표기하기도 함 \n",
    "#[2,2,3] 3차원 텐서를 2차원 텐서로 변경 (-1,3) -> 열은 정해져 있고 행의 갯수를 알아서 지정해줌\n",
    "#12개 요소 구성된 3차원 텐서 -> (행:?, 열:3) => 행:4 =>(4,3)\n",
    "ft.view([-1,3]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2330f750",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft.view([-1,5]) \n",
    "#고정하고자 하는 열이 전체에서 나눠 떨어 져야함으로 에러발생"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "99105d3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  1.,  2.],\n",
       "        [ 3.,  4.,  5.],\n",
       "        [ 6.,  7.,  8.],\n",
       "        [ 9., 10., 11.]])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft.view([4,-1]) #행은 4개로 고정, 열은 알아서 계산해라"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "e482089d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.,  1.,  2.]],\n",
       "\n",
       "        [[ 3.,  4.,  5.]],\n",
       "\n",
       "        [[ 6.,  7.,  8.]],\n",
       "\n",
       "        [[ 9., 10., 11.]]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft  #(2,2,3) -> (?,1,3)\n",
    "ft.view([-1,1,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "c3aea03f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.],\n",
       "        [1.],\n",
       "        [2.]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft=torch.FloatTensor([[0],[1],[2]])\n",
    "ft  # 3*1 행렬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "48cb26c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 2.])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft.squeeze()  #크키가 1인 차원을 제거 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "2f0c8bd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1.],\n",
       "        [1., 2.],\n",
       "        [2., 3.]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft2=torch.FloatTensor([[0,1],[1,2],[2,3]])\n",
    "ft2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "f1db080a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1.],\n",
       "        [1., 2.],\n",
       "        [2., 3.]])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft2.squeeze()  #행 크기 :3, 열 크기 :2 -> 크기가 1인 차원이 없으므로 제거 작업 수행하지 않음 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "030ae93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#unsqueeze : 크기가 1인 차원을 특정 위치에 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "4fe44861",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 2.])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft = torch.Tensor([0, 1, 2])\n",
    "ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "7aa6f395",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 2.]])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft.unsqueeze(0)  #크기가 1인 차원이 첫번째 축에 추가 (1차원 ->2차원) -> (1,3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "4efaac27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.],\n",
       "        [1.],\n",
       "        [2.]])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft.unsqueeze(1)  #크기가 1인 차원이 두번째 축에 추가 (1차원 ->2차원) ->(3,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "a5a6ed99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "lt = torch.LongTensor([1, 2, 3, 4])\n",
    "print(lt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "d6989f44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3., 4.])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lt.float() #일괄적으로 float형태로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "abf0a74f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 0, 1, 0], dtype=torch.uint8)\n"
     ]
    }
   ],
   "source": [
    "bt = torch.ByteTensor([True,False,True,False])\n",
    "print(bt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "246dbfaf",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "value cannot be converted to type uint8 without overflow",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[106], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m bt \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mByteTensor([\u001b[38;5;241m123456789876541\u001b[39m,\u001b[38;5;28;01mFalse\u001b[39;00m,\u001b[38;5;28;01mTrue\u001b[39;00m,\u001b[38;5;28;01mFalse\u001b[39;00m])\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(bt)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: value cannot be converted to type uint8 without overflow"
     ]
    }
   ],
   "source": [
    "bt = torch.ByteTensor([123456789876541,False,True,False])\n",
    "print(bt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "0a90cc26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.2312e+18, 0.0000e+00, 1.0000e+00, 0.0000e+00])\n"
     ]
    }
   ],
   "source": [
    "bt = torch.FloatTensor([1231242443567564354,False,True,False])\n",
    "print(bt)\n",
    "#Byte 텐서보다 플롯 텐서가 출력 가능 값이 더 커서 출력됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "a21d532c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0, 1, 0])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bt.long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd74788e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "a77ce331",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.FloatTensor([[1, 2], [3, 4]])\n",
    "y = torch.FloatTensor([[5, 6], [7, 8]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "2546373a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2.],\n",
       "        [3., 4.]])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "6d148b2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5., 6.],\n",
       "        [7., 8.]])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "1f14009d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2.],\n",
       "        [3., 4.],\n",
       "        [5., 6.],\n",
       "        [7., 8.]])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([x,y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "08f9a034",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2.],\n",
       "        [3., 4.],\n",
       "        [5., 6.],\n",
       "        [7., 8.]])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([x,y], dim=0)  #dim=0을 줌으로 첫번째 차원을 기준으로 연결됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "dfdced4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 5., 6.],\n",
       "        [3., 4., 7., 8.]])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([x,y], dim=1)  #두번째 차원을 기준으로 연결됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "48b65e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.FloatTensor([1, 4])\n",
    "y = torch.FloatTensor([2, 5])\n",
    "z = torch.FloatTensor([3, 6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "8ae705fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 6.])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "cb070a33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 4.],\n",
       "        [3., 6.],\n",
       "        [2., 5.]])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.stack([x,z,y]) #기입한 순서대로 합쳐짐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "9b209188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 1., 2.],\n",
      "        [2., 1., 0.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.FloatTensor([[0, 1, 2], [2, 1, 0]])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "9e1e1615",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#텐서의 크기는 그대로 두되, 새롭게 0 또는 1로 값을 채우는것 \n",
    "torch.ones_like(x)  # ->shape은 그대로, 값은 모두 1로 채워짐\n",
    "torch.zeros_like(x)  #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "3a96c568",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.FloatTensor([[1, 2], [3, 4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "dc0a2b61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2.],\n",
       "        [3., 4.]])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "a98516bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 4.],\n",
       "        [6., 8.]])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "e43e3039",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 4.],\n",
       "        [6., 8.]])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.mul(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "9c94c8c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 4.],\n",
       "        [6., 8.]])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.mul_(2) #_를 써주면 inplace함수 처럼 기존 데이터 바꿔줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "2916f9ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 4.],\n",
       "        [6., 8.]])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "003ea968",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = 0  #전역 변수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "87b69af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 지역변수 :변수명은 같지만 두개의 변수는 다른 변수다 , 함수 내부에 생성된 변수는 함수 블럭 안에서만 사용되어지는 변수로 지역변수라 함\n",
    "def add(num):\n",
    "    global result   #global을 사용하면 함수 안에 없어도 변수 사용가능 \n",
    "    #result=1\n",
    "    result +=num\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "9008f6cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "d23b8aa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "60a70975",
   "metadata": {},
   "outputs": [],
   "source": [
    "result1 = 0\n",
    "result2 = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b33f45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add1(num):\n",
    "    global result1\n",
    "    result1 += num\n",
    "    return result1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "4775e1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add2(num):\n",
    "    global result2\n",
    "    result2 += num\n",
    "    return result2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "49d46246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "print(add1(3))\n",
    "print(add1(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "10391021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "print(add2(2))\n",
    "print(add2(6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "7edd12dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(result1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "82ce61a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Calculator:\n",
    "    def __init__(self):  #클래스 -> 객체 생성될때 자동 호출(생성자 함수)\n",
    "        self.result = 0\n",
    "        print(\"생성자 호출됨\")\n",
    "    \n",
    "    def add(self, num): \n",
    "        self.result += num\n",
    "        print(\"add함수 호출됨\")\n",
    "        return self.result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "f919efd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "생성자 호출됨\n",
      "생성자 호출됨\n"
     ]
    }
   ],
   "source": [
    "cal1=Calculator()  #클래스 ->객체 생성\n",
    "cal2=Calculator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "175e5fbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add함수 호출됨\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cal1.add(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "769d9a3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add함수 호출됨\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cal1.add(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "1ca58e06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add함수 호출됨\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cal2.add(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "960cc93c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add함수 호출됨\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cal2.add(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "6cb4727b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "e97c9620",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1fc93b3c070>"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "fe043eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.FloatTensor([[1], [2], [3]])\n",
    "y_train = torch.FloatTensor([[2], [4], [6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "7e64f9a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1])"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "33225db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "W=torch.zeros(1,requires_grad=True)  #requires_grad=True는 W는 변수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "02823afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "b=torch.zeros(1,requires_grad=True) #requires_grad=True는 b는 변수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "db33c77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#초기 모델 가설 함수 : y = 0*x + 0\n",
    "hx=W * x_train + b  #예측값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "76e454bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.],\n",
       "        [0.],\n",
       "        [0.]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "d26ba0e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(18.6667, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # cost\n",
    "    \n",
    "cost=torch.mean((hx - y_train) ** 2)\n",
    "cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "f39d40f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=optim.SGD([W,b],lr=0.01) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "cf29ccf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.zero_grad()  #미분을 해서 구한 기울기를 0으로 초기화 해줌\n",
    "cost.backward()  #W, b에 대한 기울기가 계산\n",
    "optimizer.step() #W,b에 대한 업데이트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "adcd3cee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.35271114110946655 0.15093332529067993 14.770962715148926\n",
      "100 1.746303915977478 0.5766831636428833 0.04793928191065788\n",
      "200 1.8005797863006592 0.45332908630371094 0.02962353825569153\n",
      "300 1.8432375192642212 0.3563580811023712 0.018305568024516106\n",
      "400 1.876770257949829 0.28012996912002563 0.011311731301248074\n",
      "500 1.9031305313110352 0.22020739316940308 0.00698992470279336\n",
      "600 1.923851728439331 0.17310291528701782 0.004319347441196442\n",
      "700 1.940140724182129 0.13607460260391235 0.0026691032107919455\n",
      "800 1.9529448747634888 0.10696704685688019 0.001649328856728971\n",
      "900 1.9630104303359985 0.08408597856760025 0.0010191872715950012\n",
      "1000 1.970922827720642 0.06609929352998734 0.0006298050284385681\n",
      "1100 1.9771424531936646 0.05196019262075424 0.0003891797096002847\n",
      "1200 1.9820321798324585 0.04084517061710358 0.0002404868573648855\n",
      "1300 1.9858757257461548 0.03210793808102608 0.00014860653027426451\n",
      "1400 1.9888969659805298 0.025239810347557068 9.182951907860115e-05\n",
      "1500 1.99127197265625 0.019840871915221214 5.674454223481007e-05\n",
      "1600 1.9931389093399048 0.015596716664731503 3.506506254780106e-05\n",
      "1700 1.994606614112854 0.01226049941033125 2.1668203771696426e-05\n",
      "1800 1.9957603216171265 0.009637854993343353 1.3389115338213742e-05\n",
      "1900 1.9966671466827393 0.007576377131044865 8.274880201497581e-06\n"
     ]
    }
   ],
   "source": [
    "optimizer=optim.SGD([W,b],lr=0.01) \n",
    "for epoch in range(2000):\n",
    "    hx=W * x_train + b\n",
    "    cost=torch.mean((hx - y_train) ** 2)\n",
    "    optimizer.zero_grad()  #미분을 해서 구한 기울기를 0으로 초기화 해줌, 안하면 이전에 구한 기울기 계속 더해짐\n",
    "    cost.backward()  #W, b에 대한 기울기가 계산\n",
    "    optimizer.step() #W,b에 대한 업데이트\n",
    "    if epoch%100 ==0:\n",
    "        print(epoch, W.item(), b.item(), cost.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "aa1edf0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.9974], requires_grad=True)"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W   #W:2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "a88d6b95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0060], requires_grad=True)"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b    #b:0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "23a91986",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.9973737001419067"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W.item() #W가 가지고 있는 값 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "db5fa7f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.992838663514704"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W.item()*5 + b.item()   #예측값 구함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "56bad942",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = torch.tensor(2.0, requires_grad=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "042be325",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=w**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "bfee59b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4., grad_fn=<PowBackward0>)"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "c736d0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "z=2*y+5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "9b3ca6c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(13., grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "289ae8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "z.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "08529d0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(8.)"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.grad  #z수식을 w로 미분한 값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b56e927",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "1d5126f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_train = torch.FloatTensor([[73], [93], [89], [96], [73]])\n",
    "x2_train = torch.FloatTensor([[80], [88], [91], [98], [66]])\n",
    "x3_train = torch.FloatTensor([[75], [93], [90], [100], [70]])\n",
    "y_train = torch.FloatTensor([[152], [185], [180], [196], [142]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "b0fb071f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 1])"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "96681db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = torch.zeros(1, requires_grad=True)\n",
    "w2 = torch.zeros(1, requires_grad=True)\n",
    "w3 = torch.zeros(1, requires_grad=True)\n",
    "b = torch.zeros(1, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "d03067d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.7570484280586243 0.5713934898376465 0.6820759177207947 0.01059654913842678 0.7543893456459045\n",
      "10 0.7573939561843872 0.5710384249687195 0.682084858417511 0.010609765537083149 0.751927375793457\n",
      "20 0.7577386498451233 0.5706843137741089 0.6820935606956482 0.010622975416481495 0.7494856119155884\n",
      "30 0.7580825686454773 0.5703312754631042 0.6821020841598511 0.010636175982654095 0.7470517754554749\n",
      "40 0.7584256529808044 0.5699792504310608 0.6821103692054749 0.010649370029568672 0.7446351051330566\n",
      "50 0.7587679028511047 0.5696282982826233 0.6821185350418091 0.010662556625902653 0.7422196269035339\n",
      "60 0.7591094374656677 0.5692782998085022 0.6821264624595642 0.010675736702978611 0.7398267984390259\n",
      "70 0.7594501376152039 0.5689293146133423 0.682134211063385 0.010688906535506248 0.7374515533447266\n",
      "80 0.7597898840904236 0.5685813426971436 0.6821417808532715 0.010702070780098438 0.7350757718086243\n",
      "90 0.7601290345191956 0.5682343244552612 0.6821490526199341 0.010715227574110031 0.7327166199684143\n",
      "100 0.7604672312736511 0.5678883194923401 0.6821562051773071 0.010728377848863602 0.730373203754425\n",
      "110 0.7608045935630798 0.5675433278083801 0.6821632385253906 0.010741518810391426 0.7280388474464417\n",
      "120 0.7611411809921265 0.5671993494033813 0.682170033454895 0.010754653252661228 0.7257146835327148\n",
      "130 0.7614770531654358 0.5668563842773438 0.6821767091751099 0.010767780244350433 0.7234158515930176\n",
      "140 0.7618120312690735 0.5665143728256226 0.6821832656860352 0.010780896060168743 0.721122682094574\n",
      "150 0.7621462345123291 0.566173255443573 0.6821894645690918 0.01079400721937418 0.7188307642936707\n",
      "160 0.7624796032905579 0.5658332109451294 0.6821955442428589 0.01080711092799902 0.716564953327179\n",
      "170 0.7628123164176941 0.5654940605163574 0.6822015047073364 0.010820206254720688 0.7143115997314453\n",
      "180 0.7631440162658691 0.5651558637619019 0.6822073459625244 0.010833293199539185 0.7120558023452759\n",
      "190 0.7634751796722412 0.5648186802864075 0.6822128891944885 0.010846374556422234 0.7098273038864136\n",
      "200 0.7638053894042969 0.5644825100898743 0.6822182536125183 0.010859447531402111 0.707607090473175\n",
      "210 0.7641348242759705 0.5641473531723022 0.6822235584259033 0.010872513055801392 0.7053872346878052\n",
      "220 0.7644636034965515 0.5638130903244019 0.6822284460067749 0.0108855701982975 0.7031837701797485\n",
      "230 0.7647915482521057 0.5634798407554626 0.6822332143783569 0.010898618958890438 0.7010038495063782\n",
      "240 0.7651186585426331 0.5631474852561951 0.6822379231452942 0.010911659337580204 0.698818027973175\n",
      "250 0.7654449939727783 0.5628160834312439 0.6822423934936523 0.010924691334366798 0.6966522336006165\n",
      "260 0.765770673751831 0.5624856352806091 0.6822466254234314 0.010937717743217945 0.6945029497146606\n",
      "270 0.7660955190658569 0.5621562004089355 0.6822507381439209 0.010950736701488495 0.6923564672470093\n",
      "280 0.766419529914856 0.5618276596069336 0.6822547912597656 0.010963747277855873 0.6902180314064026\n",
      "290 0.7667428851127625 0.5614999532699585 0.6822585463523865 0.01097674947232008 0.6881049871444702\n",
      "300 0.7670654058456421 0.5611733794212341 0.682262122631073 0.010989745147526264 0.6859889626502991\n",
      "310 0.7673870921134949 0.5608475804328918 0.6822656989097595 0.011002734303474426 0.6838871240615845\n",
      "320 0.7677080631256104 0.5605227947235107 0.6822689175605774 0.011015715077519417 0.6818143725395203\n",
      "330 0.7680284380912781 0.5601989030838013 0.6822719573974609 0.011028689332306385 0.6797288656234741\n",
      "340 0.7683479189872742 0.559876024723053 0.6822748780250549 0.011041656136512756 0.677672266960144\n",
      "350 0.7686666250228882 0.5595539808273315 0.6822776794433594 0.011054614558815956 0.6756054162979126\n",
      "360 0.7689846754074097 0.5592329502105713 0.6822801828384399 0.011067568324506283 0.6735566854476929\n",
      "370 0.7693019509315491 0.5589128732681274 0.682282567024231 0.011080513708293438 0.6715232133865356\n",
      "380 0.7696183323860168 0.5585936307907104 0.6822848320007324 0.011093449778854847 0.6695051789283752\n",
      "390 0.7699340581893921 0.5582753419876099 0.6822868585586548 0.011106380261480808 0.6674872040748596\n",
      "400 0.7702491283416748 0.5579580664634705 0.6822887063026428 0.011119304224848747 0.6654970645904541\n",
      "410 0.7705633640289307 0.5576416254043579 0.6822904944419861 0.011132219806313515 0.6635040044784546\n",
      "420 0.7708768248558044 0.557326078414917 0.6822920441627502 0.01114512700587511 0.6615192890167236\n",
      "430 0.7711896300315857 0.5570114254951477 0.6822934150695801 0.011158027686178684 0.6595500111579895\n",
      "440 0.7715016007423401 0.55669766664505 0.6822946071624756 0.011170920915901661 0.6575866341590881\n",
      "450 0.7718129754066467 0.5563848614692688 0.6822956800460815 0.011183805763721466 0.6556401252746582\n",
      "460 0.772123396396637 0.5560729503631592 0.6822965741157532 0.011196684092283249 0.6536882519721985\n",
      "470 0.772433340549469 0.5557618737220764 0.6822972893714905 0.011209554970264435 0.6517612338066101\n",
      "480 0.7727424502372742 0.5554517507553101 0.6822978854179382 0.011222418397665024 0.6498408317565918\n",
      "490 0.773050844669342 0.5551424622535706 0.6822983622550964 0.011235276237130165 0.6479401588439941\n",
      "500 0.7733585238456726 0.5548340678215027 0.6822985410690308 0.011248128488659859 0.6460351943969727\n",
      "510 0.7736654877662659 0.5545266270637512 0.6822985410690308 0.011260971426963806 0.6441349983215332\n",
      "520 0.7739716172218323 0.5542200803756714 0.682298481464386 0.011273807846009731 0.6422594785690308\n",
      "530 0.7742771506309509 0.5539143681526184 0.6822982430458069 0.01128663681447506 0.6403905749320984\n",
      "540 0.774582028388977 0.5536096096038818 0.6822977066040039 0.011299461126327515 0.6385337114334106\n",
      "550 0.7748861312866211 0.5533056855201721 0.6822971105575562 0.011312276124954224 0.636682391166687\n",
      "560 0.7751893997192383 0.5530025959014893 0.6822965145111084 0.011325081810355186 0.6348423957824707\n",
      "570 0.7754919528961182 0.552700400352478 0.6822956204414368 0.011337881907820702 0.6330119967460632\n",
      "580 0.7757939100265503 0.5523990988731384 0.682294487953186 0.01135067455470562 0.6311962008476257\n",
      "590 0.7760951519012451 0.5520986914634705 0.6822932958602905 0.01136346161365509 0.6293754577636719\n",
      "600 0.7763956785202026 0.5517990589141846 0.682292103767395 0.01137624029070139 0.6275851726531982\n",
      "610 0.7766954302787781 0.5515003204345703 0.6822904944419861 0.011389011517167091 0.6257830858230591\n",
      "620 0.7769945859909058 0.5512024760246277 0.6822887659072876 0.01140177808701992 0.6240046620368958\n",
      "630 0.7772929668426514 0.5509054660797119 0.6822869777679443 0.011414537206292152 0.6222284436225891\n",
      "640 0.7775906324386597 0.5506093502044678 0.6822850108146667 0.011427287943661213 0.620458722114563\n",
      "650 0.7778877019882202 0.5503140687942505 0.6822828054428101 0.011440033093094826 0.6186941862106323\n",
      "660 0.7781840562820435 0.5500198006629944 0.682280421257019 0.011452771723270416 0.6169600486755371\n",
      "670 0.7784795761108398 0.5497261881828308 0.6822779774665833 0.01146550290286541 0.6152205467224121\n",
      "680 0.778774619102478 0.5494334697723389 0.6822752952575684 0.011478225700557232 0.6134853363037109\n",
      "690 0.7790688872337341 0.5491415858268738 0.6822724342346191 0.011490942910313606 0.6117599010467529\n",
      "700 0.7793624997138977 0.5488505363464355 0.6822694540023804 0.011503651738166809 0.6100499033927917\n",
      "710 0.779655396938324 0.5485603213310242 0.6822664141654968 0.011516354978084564 0.6083515882492065\n",
      "720 0.7799475789070129 0.5482710003852844 0.682263195514679 0.011529050767421722 0.6066571474075317\n",
      "730 0.7802391052246094 0.5479825139045715 0.682259738445282 0.011541741900146008 0.604971706867218\n",
      "740 0.7805299162864685 0.5476948618888855 0.6822561621665955 0.011554425582289696 0.6033008098602295\n",
      "750 0.7808200716972351 0.5474079847335815 0.6822524666786194 0.011567101813852787 0.6016351580619812\n",
      "760 0.7811094522476196 0.5471220016479492 0.6822486519813538 0.011579769663512707 0.5999840497970581\n",
      "770 0.7813982367515564 0.5468368530273438 0.6822446584701538 0.011592431925237179 0.5983220934867859\n",
      "780 0.7816864252090454 0.5465525388717651 0.6822404861450195 0.011605088599026203 0.596681535243988\n",
      "790 0.7819738388061523 0.5462689995765686 0.6822362542152405 0.011617735959589481 0.5950376987457275\n",
      "800 0.7822605967521667 0.5459862947463989 0.6822317242622375 0.011630377732217312 0.5934258699417114\n",
      "810 0.7825468182563782 0.5457044243812561 0.6822270750999451 0.011643010191619396 0.5918129086494446\n",
      "820 0.7828322052955627 0.5454233884811401 0.682222306728363 0.011655637994408607 0.5901970267295837\n",
      "830 0.7831169366836548 0.5451431274414062 0.6822174191474915 0.011668260209262371 0.5886046886444092\n",
      "840 0.7834010720252991 0.5448637008666992 0.6822124719619751 0.011680875904858112 0.5870105028152466\n",
      "850 0.7836846113204956 0.5445850491523743 0.6822071075439453 0.011693486012518406 0.5854207277297974\n",
      "860 0.7839674353599548 0.5443071722984314 0.6822018027305603 0.011706087738275528 0.583848774433136\n",
      "870 0.7842495441436768 0.5440301895141602 0.682196319103241 0.011718682013452053 0.5822873711585999\n",
      "880 0.7845310568809509 0.5437539219856262 0.6821906566619873 0.011731269769370556 0.5807297825813293\n",
      "890 0.7848118543624878 0.5434785485267639 0.6821849346160889 0.011743851937353611 0.5791810154914856\n",
      "900 0.7850920557975769 0.5432040691375732 0.6821789741516113 0.011756429448723793 0.5776429176330566\n",
      "910 0.7853716015815735 0.5429302453994751 0.682172954082489 0.011768997646868229 0.5761076807975769\n",
      "920 0.7856505513191223 0.5426571369171143 0.6821666955947876 0.011781561188399792 0.5745881795883179\n",
      "930 0.7859288454055786 0.542384922504425 0.6821601986885071 0.011794116348028183 0.5730651617050171\n",
      "940 0.7862064242362976 0.5421135425567627 0.6821536421775818 0.011806667782366276 0.571548342704773\n",
      "950 0.7864833474159241 0.5418428182601929 0.6821470856666565 0.011819211766123772 0.5700544118881226\n",
      "960 0.7867596745491028 0.5415729880332947 0.6821403503417969 0.011831747367978096 0.5685513019561768\n",
      "970 0.787035346031189 0.5413038730621338 0.6821333765983582 0.011844275519251823 0.5670703649520874\n",
      "980 0.7873103618621826 0.5410355925559998 0.6821262836456299 0.011856797151267529 0.5655955076217651\n",
      "990 0.7875847816467285 0.5407680869102478 0.6821191310882568 0.01186931412667036 0.5641125440597534\n",
      "1000 0.7878585457801819 0.5405014157295227 0.6821117401123047 0.011881821788847446 0.5626477599143982\n",
      "1010 0.7881316542625427 0.5402355194091797 0.682104229927063 0.011894328519701958 0.561205267906189\n",
      "1020 0.7884041666984558 0.539970338344574 0.6820964813232422 0.011906826868653297 0.559752881526947\n",
      "1030 0.7886760830879211 0.5397059321403503 0.6820887327194214 0.01191931776702404 0.5583102107048035\n",
      "1040 0.788947343826294 0.539442241191864 0.6820808053016663 0.01193180214613676 0.5568717122077942\n",
      "1050 0.7892179489135742 0.5391793251037598 0.6820727586746216 0.011944280005991459 0.5554524064064026\n",
      "1060 0.7894879579544067 0.5389172434806824 0.6820645332336426 0.01195675041526556 0.554030179977417\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1070 0.7897573113441467 0.5386559963226318 0.682056188583374 0.011969216167926788 0.5526240468025208\n",
      "1080 0.7900260090827942 0.538395345211029 0.6820477843284607 0.01198167447000742 0.5512160062789917\n",
      "1090 0.7902941107749939 0.5381355285644531 0.6820391416549683 0.011994126252830029 0.549821138381958\n",
      "1100 0.7905616164207458 0.5378764867782593 0.682030439376831 0.01200657244771719 0.5484288930892944\n",
      "1110 0.79082852602005 0.5376182198524475 0.6820214986801147 0.012019013054668903 0.5470463037490845\n",
      "1120 0.7910947799682617 0.5373606085777283 0.6820125579833984 0.01203144621104002 0.5456733107566833\n",
      "1130 0.7913604974746704 0.5371037721633911 0.6820034384727478 0.012043870985507965 0.5442969799041748\n",
      "1140 0.7916256189346313 0.536847710609436 0.6819939613342285 0.012056292966008186 0.5429391860961914\n",
      "1150 0.7918899655342102 0.536592423915863 0.681984543800354 0.012068708427250385 0.5415868163108826\n",
      "1160 0.7921538352966309 0.5363379120826721 0.6819750070571899 0.012081117369234562 0.5402359366416931\n",
      "1170 0.792417049407959 0.5360841751098633 0.6819654107093811 0.012093518860638142 0.538903534412384\n",
      "1180 0.7926797270774841 0.5358310341835022 0.6819554567337036 0.012105914764106274 0.5375651717185974\n",
      "1190 0.7929418087005615 0.5355786681175232 0.6819453835487366 0.012118303216993809 0.5362352132797241\n",
      "1200 0.7932031750679016 0.535327136516571 0.6819353103637695 0.012130685150623322 0.5349233746528625\n",
      "1210 0.7934640049934387 0.5350762605667114 0.6819251179695129 0.012143061496317387 0.533603310585022\n",
      "1220 0.7937242984771729 0.5348260402679443 0.681914746761322 0.012155430391430855 0.5323074460029602\n",
      "1230 0.7939839959144592 0.5345767140388489 0.681904137134552 0.012167795561254025 0.5310013890266418\n",
      "1240 0.7942430973052979 0.534328043460846 0.6818934082984924 0.012180154211819172 0.5297077298164368\n",
      "1250 0.7945014834403992 0.5340801477432251 0.6818826198577881 0.012192506343126297 0.5284211039543152\n",
      "1260 0.7947593331336975 0.533832848072052 0.681871771812439 0.0122048519551754 0.5271428823471069\n",
      "1270 0.7950165867805481 0.5335863828659058 0.6818608045578003 0.01221719104796648 0.5258625745773315\n",
      "1280 0.7952733039855957 0.5333406329154968 0.6818495392799377 0.012229523621499538 0.5246065258979797\n",
      "1290 0.7955294847488403 0.5330955386161804 0.6818382740020752 0.012241851538419724 0.5233457684516907\n",
      "1300 0.7957849502563477 0.5328510999679565 0.6818269491195679 0.012254172936081886 0.5220927596092224\n",
      "1310 0.7960398197174072 0.5326074361801147 0.681815505027771 0.012266487814486027 0.520851731300354\n",
      "1320 0.7962941527366638 0.5323644876480103 0.681803822517395 0.01227879710495472 0.5196069478988647\n",
      "1330 0.7965479493141174 0.5321223139762878 0.6817919611930847 0.01229109987616539 0.5183617472648621\n",
      "1340 0.7968012094497681 0.531880795955658 0.6817800402641296 0.012303397059440613 0.5171369910240173\n",
      "1350 0.7970538139343262 0.5316399931907654 0.681768000125885 0.012315690517425537 0.5159180760383606\n",
      "1360 0.7973057627677917 0.5313999652862549 0.6817558407783508 0.012327974662184715 0.5147090554237366\n",
      "1370 0.7975571751594543 0.5311605930328369 0.6817435026168823 0.01234025415033102 0.5134936571121216\n",
      "1380 0.7978081703186035 0.5309219360351562 0.6817310452461243 0.012352528981864452 0.512298583984375\n",
      "1390 0.7980583906173706 0.5306839346885681 0.6817185282707214 0.012364794500172138 0.5110927820205688\n",
      "1400 0.798308253288269 0.5304465293884277 0.6817058324813843 0.012377053499221802 0.509905993938446\n",
      "1410 0.798557460308075 0.5302099585533142 0.6816929578781128 0.012389309704303741 0.508719265460968\n",
      "1420 0.7988060116767883 0.5299741625785828 0.6816799640655518 0.012401560321450233 0.5075417757034302\n",
      "1430 0.7990540862083435 0.5297390222549438 0.6816668510437012 0.012413806281983852 0.5063693523406982\n",
      "1440 0.7993014454841614 0.5295045375823975 0.6816537380218506 0.0124260438606143 0.5051999092102051\n",
      "1450 0.799548327922821 0.5292706489562988 0.6816405057907104 0.01243827398866415 0.50404953956604\n",
      "1460 0.7997946739196777 0.5290374755859375 0.681627094745636 0.012450498528778553 0.502890944480896\n",
      "1470 0.8000404834747314 0.5288050174713135 0.6816134452819824 0.012462717480957508 0.5017502903938293\n",
      "1480 0.800285816192627 0.5285733342170715 0.6815997362136841 0.012474932707846165 0.5005990266799927\n",
      "1490 0.8005304336547852 0.5283421874046326 0.6815860271453857 0.012487141415476799 0.4994521141052246\n",
      "1500 0.8007745146751404 0.5281117558479309 0.6815721988677979 0.012499341741204262 0.4983166754245758\n",
      "1510 0.8010180592536926 0.5278819799423218 0.6815581321716309 0.012511537410318851 0.49720558524131775\n",
      "1520 0.8012610673904419 0.52765291929245 0.6815439462661743 0.012523727491497993 0.4960854649543762\n",
      "1530 0.801503598690033 0.5274245738983154 0.6815296411514282 0.012535911053419113 0.49497437477111816\n",
      "1540 0.8017455339431763 0.5271967649459839 0.6815153360366821 0.01254808995872736 0.493872731924057\n",
      "1550 0.8019869327545166 0.5269696712493896 0.6815007925033569 0.012560262344777584 0.4927574694156647\n",
      "1560 0.802227795124054 0.5267433524131775 0.6814860701560974 0.012572427280247211 0.49166545271873474\n",
      "1570 0.8024680614471436 0.5265176892280579 0.6814712285995483 0.01258458849042654 0.49057430028915405\n",
      "1580 0.802707850933075 0.5262926816940308 0.6814563274383545 0.012596742250025272 0.48948878049850464\n",
      "1590 0.802946925163269 0.5260682702064514 0.6814414262771606 0.012608889490365982 0.4884119927883148\n",
      "1600 0.8031855225563049 0.5258445143699646 0.6814264059066772 0.012621033936738968 0.4873408377170563\n",
      "1610 0.8034236431121826 0.5256213545799255 0.6814111471176147 0.012633170932531357 0.48626941442489624\n",
      "1620 0.8036612868309021 0.5253989696502686 0.6813957691192627 0.012645304203033447 0.4852028489112854\n",
      "1630 0.8038983345031738 0.5251772999763489 0.6813802719116211 0.01265743002295494 0.48414546251296997\n",
      "1640 0.8041348457336426 0.5249561071395874 0.6813647747039795 0.012669548392295837 0.48309391736984253\n",
      "1650 0.8043708205223083 0.5247356295585632 0.6813490390777588 0.01268166396766901 0.48204582929611206\n",
      "1660 0.8046063184738159 0.5245158076286316 0.6813332438468933 0.012693772092461586 0.48099857568740845\n",
      "1670 0.804841160774231 0.5242967009544373 0.6813172698020935 0.012705877423286438 0.479969322681427\n",
      "1680 0.8050755858421326 0.5240782499313354 0.6813011765480042 0.012717975303530693 0.47894150018692017\n",
      "1690 0.8053093552589417 0.5238603949546814 0.6812850832939148 0.012730065733194351 0.47791561484336853\n",
      "1700 0.8055426478385925 0.5236431360244751 0.6812688708305359 0.012742152437567711 0.4768880009651184\n",
      "1710 0.8057754635810852 0.5234264731407166 0.6812524795532227 0.012754231691360474 0.4758680462837219\n",
      "1720 0.8060078024864197 0.5232105851173401 0.6812359094619751 0.012766307219862938 0.47486695647239685\n",
      "1730 0.806239664554596 0.5229952931404114 0.681219220161438 0.012778377160429955 0.4738537669181824\n",
      "1740 0.8064708709716797 0.5227805972099304 0.6812025308609009 0.012790439650416374 0.4728616178035736\n",
      "1750 0.80670166015625 0.5225664973258972 0.6811856627464294 0.012802496552467346 0.47186049818992615\n",
      "1760 0.8069318532943726 0.5223531126976013 0.6811687350273132 0.012814548797905445 0.4708658754825592\n",
      "1770 0.8071616291999817 0.5221403241157532 0.6811515688896179 0.012826597318053246 0.46988973021507263\n",
      "1780 0.8073909282684326 0.5219281911849976 0.6811343431472778 0.012838639318943024 0.4689098000526428\n",
      "1790 0.8076195120811462 0.5217165946960449 0.681117057800293 0.012850673869252205 0.46792668104171753\n",
      "1800 0.8078476190567017 0.5215057134628296 0.6810997724533081 0.012862705625593662 0.4669612944126129\n",
      "1810 0.8080751895904541 0.521295428276062 0.6810823082923889 0.012874729000031948 0.4659915864467621\n",
      "1820 0.8083022832870483 0.521085798740387 0.681064784526825 0.01288674958050251 0.46503716707229614\n",
      "1830 0.8085288405418396 0.5208768844604492 0.6810469627380371 0.01289876364171505 0.4640820026397705\n",
      "1840 0.8087549209594727 0.5206685066223145 0.6810290813446045 0.012910771183669567 0.46313029527664185\n",
      "1850 0.8089805245399475 0.5204606652259827 0.6810111999511719 0.01292277593165636 0.46217870712280273\n",
      "1860 0.8092056512832642 0.5202533602714539 0.6809931993484497 0.012934771366417408 0.4612451493740082\n",
      "1870 0.8094303011894226 0.5200468301773071 0.680975079536438 0.012946763075888157 0.46031078696250916\n",
      "1880 0.8096544146537781 0.5198409557342529 0.6809566617012024 0.012958749197423458 0.459369033575058\n",
      "1890 0.8098780512809753 0.5196356177330017 0.680938184261322 0.012970727868378162 0.45844966173171997\n",
      "1900 0.8101011514663696 0.5194308757781982 0.6809197068214417 0.012982702814042568 0.45752841234207153\n",
      "1910 0.8103237748146057 0.5192267298698425 0.6809011697769165 0.012994671240448952 0.45660561323165894\n",
      "1920 0.8105458617210388 0.5190231800079346 0.680882453918457 0.013006636872887611 0.45570412278175354\n",
      "1930 0.8107675909996033 0.5188202857971191 0.6808634996414185 0.013018595054745674 0.4547831416130066\n",
      "1940 0.81098872423172 0.5186179280281067 0.6808445453643799 0.01303054764866829 0.4538843631744385\n",
      "1950 0.8112093806266785 0.5184162855148315 0.6808254718780518 0.013042494654655457 0.45297902822494507\n",
      "1960 0.811429500579834 0.5182151198387146 0.6808063983917236 0.013054435141384602 0.45209580659866333\n",
      "1970 0.8116490840911865 0.5180145502090454 0.6807872653007507 0.013066374696791172 0.4512038826942444\n",
      "1980 0.8118681907653809 0.5178146362304688 0.6807678937911987 0.013078304938971996 0.45031672716140747\n",
      "1990 0.8120869398117065 0.5176153182983398 0.6807484030723572 0.013090231455862522 0.449432909488678\n"
     ]
    }
   ],
   "source": [
    "optimizer=optim.SGD([w1,w2,w3,b],lr=1e-5) #0.01 <= lr <= 0.001\n",
    "#1* 10의 -5 승 = 1* 0.00001 = 1e-5\n",
    "\n",
    "for epoch in range(2000):\n",
    "    hx=w1 * x1_train + w2 * x2_train+ w3 * x3_train + b\n",
    "    cost=torch.mean((hx - y_train)**2)\n",
    "    optimizer.zero_grad()#미분을 해서 구한 기울기를 0으로 초기화해줌\n",
    "    cost.backward() #W, b에 대한 기울기가 계산\n",
    "    optimizer.step()#W,b에 대한 업데이트\n",
    "    if epoch%10 ==0:\n",
    "        \n",
    "        print(epoch, w1.item(), w2.item(), w3.item(), b.item(), cost.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "00802d16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "180.95364973694086"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " w1.item()*90+ w2.item()*90+ w3.item()*90+ b.item()\n",
    "#예상 수능 점수 : 180.95..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "81ae121c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#                               x1   x2   x3\n",
    "x_train  =  torch.FloatTensor([[73,  80,  75], \n",
    "                               [93,  88,  93], \n",
    "                               [89,  91,  80], \n",
    "                               [96,  98,  100],   \n",
    "                               [73,  66,  70]])  \n",
    "y_train  =  torch.FloatTensor([[152],  [185],  [180],  [196],  [142]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "491ea310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3])\n",
      "torch.Size([5, 1])\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "3e9acfd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#w1 = torch.zeros(1, requires_grad=True)\n",
    "#w2 = torch.zeros(1, requires_grad=True)\n",
    "#w3 = torch.zeros(1, requires_grad=True)\n",
    "\n",
    "\n",
    "W = torch.zeros((3,1), requires_grad = True)\n",
    "b = torch.zeros(1, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "f320b643",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=optim.SGD([W,b],lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "ed2042c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 29661.80078125\n",
      "100 5.754572868347168\n",
      "200 5.512386322021484\n",
      "300 5.281667232513428\n",
      "400 5.061906814575195\n",
      "500 4.852423667907715\n",
      "600 4.652731418609619\n",
      "700 4.4622650146484375\n",
      "800 4.280604362487793\n",
      "900 4.107260704040527\n",
      "1000 3.941852569580078\n",
      "1100 3.7838993072509766\n",
      "1200 3.6330528259277344\n",
      "1300 3.4889779090881348\n",
      "1400 3.351316452026367\n",
      "1500 3.2197258472442627\n",
      "1600 3.0939736366271973\n",
      "1700 2.9737014770507812\n",
      "1800 2.858673334121704\n",
      "1900 2.748659133911133\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(2000):\n",
    "    hx=x_train.matmul(W) + b\n",
    "    cost=torch.mean((hx - y_train) ** 2)\n",
    "    optimizer.zero_grad()  #미분을 해서 구한 기울기를 0으로 초기화 해줌, 안하면 이전에 구한 기울기 계속 더해짐\n",
    "    cost.backward()  #W, b에 대한 기울기가 계산\n",
    "    optimizer.step() #W,b에 대한 업데이트\n",
    "    if epoch%100 ==0:\n",
    "        print(epoch, cost.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "aa646749",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "f102b4da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1fc93b3c070>"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "0fc98f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.FloatTensor([[1], [2], [3]])\n",
    "y_train = torch.FloatTensor([[2], [4], [6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4368a47a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "482cf852",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Linear(1,1)  # 입력차원, 출력차원  ->하나의 입력에 하나의 출력이 있다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "67132cc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[0.5153]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.4414], requires_grad=True)]"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.parameters())  #w,b 값\n",
    "#초기 모델 : y=0.5153 * x_train -0.4414 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "80f8b9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=torch.optim.SGD(model.parameters(),lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "9f6345c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 13.103541374206543\n",
      "100 0.00279058120213449\n",
      "200 0.00172441138420254\n",
      "300 0.0010655784280970693\n",
      "400 0.0006584661896340549\n",
      "500 0.0004068926500622183\n",
      "600 0.0002514346851967275\n",
      "700 0.00015537298168055713\n",
      "800 9.601024794392288e-05\n",
      "900 5.9327696362743154e-05\n",
      "1000 3.66610438504722e-05\n",
      "1100 2.2655576685792767e-05\n",
      "1200 1.3999051589053124e-05\n",
      "1300 8.65114816406276e-06\n",
      "1400 5.346103989722906e-06\n",
      "1500 3.3032331430149497e-06\n",
      "1600 2.04174443751981e-06\n",
      "1700 1.2618406799447257e-06\n",
      "1800 7.801028800713539e-07\n",
      "1900 4.823282324650791e-07\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(2000):\n",
    "    \n",
    "    hx = model(x_train)  #hx=x_train.matmul(W) + b\n",
    "    cost = F.mse_loss(hx, y_train)   #cost=torch.mean((hx - y_train) ** 2)\n",
    "    \n",
    "    \n",
    "    optimizer.zero_grad()  #미분을 해서 구한 기울기를 0으로 초기화 해줌, 안하면 이전에 구한 기울기 계속 더해짐\n",
    "    cost.backward()  #W, b에 대한 기울기가 계산\n",
    "    optimizer.step() #W,b에 대한 업데이트\n",
    "    if epoch%100 ==0:\n",
    "        print(epoch, cost.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "f3eb069a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[1.9994]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.0014], requires_grad=True)]"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.parameters()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "f8d11fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_var =  torch.FloatTensor([[4.0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "895d968d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[7.9989]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(new_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "1d0de840",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.FloatTensor([[73, 80, 75],\n",
    "                             [93, 88, 93],\n",
    "                             [89, 91, 90],\n",
    "                             [96, 98, 100],\n",
    "                             [73, 66, 70]])\n",
    "y_train = torch.FloatTensor([[152], [185], [180], [196], [142]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "22de27e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=nn.Linear(3,1) # 입력차원, 출력차원"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "ff20e1be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-0.1119,  0.2710, -0.5435]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.3462], requires_grad=True)]"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "5d8e0ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=torch.optim.SGD(model.parameters(), lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "286ee124",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 42134.70703125\n",
      "100 5.960053443908691\n",
      "200 5.654706954956055\n",
      "300 5.365412712097168\n",
      "400 5.091428756713867\n",
      "500 4.831833839416504\n",
      "600 4.585997104644775\n",
      "700 4.353074550628662\n",
      "800 4.132411003112793\n",
      "900 3.9234554767608643\n",
      "1000 3.7255024909973145\n",
      "1100 3.5379719734191895\n",
      "1200 3.360325574874878\n",
      "1300 3.19205641746521\n",
      "1400 3.0326738357543945\n",
      "1500 2.881699562072754\n",
      "1600 2.7386722564697266\n",
      "1700 2.603201150894165\n",
      "1800 2.4748456478118896\n",
      "1900 2.353286027908325\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(2000):\n",
    "    \n",
    "    hx = model(x_train)  #hx=x_train.matmul(W) + b\n",
    "    cost = F.mse_loss(hx, y_train)   #cost=torch.mean((hx - y_train) ** 2)\n",
    "    \n",
    "    \n",
    "    optimizer.zero_grad()  #미분을 해서 구한 기울기를 0으로 초기화 해줌, 안하면 이전에 구한 기울기 계속 더해짐\n",
    "    cost.backward()  #W, b에 대한 기울기가 계산\n",
    "    optimizer.step() #W,b에 대한 업데이트\n",
    "    if epoch%100 ==0:\n",
    "        print(epoch, cost.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "397210a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[181.3557]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_var = torch.FloatTensor([[90,90,90]])\n",
    "model(new_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "047cdc05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[0.8540, 0.8475, 0.3096]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.3568], requires_grad=True)]"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182ffc7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
